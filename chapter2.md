# 第 2 章：数据、指标与统计：从“可比”到“可信”

## 2.1 开篇与目标

在 MLLM（多模态大语言模型）的开发周期中，测评（Evaluation）往往被视为“期末考试”。然而，在工业界，尤其是涉及行车安全的驾舱一体场景中，测评更像是“体检仪”和“导航图”。如果数据存在偏差，或者尺子（指标）本身是歪的，模型的所有优化都可能是在南辕北辙。

许多团队面临的典型问题是：
*   **“体感”偏差**：开发人员觉得“效果不错”，但上线后用户投诉“听不懂人话”。
*   **刷榜陷阱**：在公开榜单上分数很高，但在特定业务场景（如车内噪音环境）下一塌糊涂。
*   **指标失灵**：生成文本通顺流畅（BLEU 分数高），但核心事实（如导航 POI）全是编造的。

本章的目标是将测评从一种“感觉不错”（Vibes-based）的玄学，转变为**“数据闭环、指标多维、统计显著”**（Data-driven, Multi-dimensional, Statistically Significant）的工程科学。

**学习目标**：
1.  **构建数据防线**：掌握数据防泄漏（Decontamination）与难例挖掘（Hard Mining）的系统方法。
2.  **精通多模态指标**：深入理解 ASR、TTS、CV、NLP 各模态的“北极星指标”与“卫兵指标”。
3.  **统计显著性分析**：学会使用 Bootstrap 和置信区间，拒绝被 0.5% 的随机波动欺骗。
4.  **掌握 LLM-as-a-Judge**：了解如何训练、校准和使用大模型作为裁判。
5.  **车舱场景落地**：建立针对驾舱环境的“硬门槛”与“影子模式”测评体系。

---

## 2.2 数据集选型与管理：地基的牢固度

### 2.2.1 数据集选型原则 (The "GOLD" Rule)
选择或构建测评数据集时，请严格遵循 **GOLD** 原则：

*   **G**round Truth Quality (真值质量)：
    *   **人工 > 合成**：尽管合成数据（如用 GPT-4 生成数据）很流行，但作为测评集的“金标准”，必须经过人工校验（Human-verified）。
    *   **多轮清洗**：真值不是绝对正确的，需建立纠错机制。
*   **O**ut-of-Distribution (分布外 - OOD)：
    *   测试集必须包含训练集中未见过的场景。如果训练全是高清图，测试必须包含夜间/模糊图。
    *   *Rule of Thumb*：测试集应当比训练集“更难、更脏、更真实”。
*   **L**icense & Privacy (合规)：
    *   确保测评集可商用。
    *   **隐私红线**：车内数据包含人脸、家庭住址语音等，入库测评前必须完成脱敏（见 2.8 节）。
*   **D**ifficulty Gradient (难度梯度)：
    *   **L1 (Sanity)**：简单的指令跟随（“打开空调”）。
    *   **L2 (Common)**：带参数的意图（“把空调调到24度并打开内循环”）。
    *   **L3 (Corner Case)**：语义歧义、多模态冲突、高噪声（“别听他的，我不冷，还是关了吧” + 背景有人说话）。

### 2.2.2 数据泄漏防护体系 (The Decontamination Pipeline)
LLM 具有极强的记忆能力。一旦测试集混入了训练数据，测评就变成了“默写”。

**常见的泄漏层级：**
1.  **Exact Match**：字符串完全一致。
2.  **Near-Duplicate**：同义词替换、图片裁剪/缩放/压缩。
3.  **Contamination via Prompt**：测试集的 Prompt 模板被写入了微调数据，导致模型学会了格式而非逻辑。
4.  **Entity Leakage**：虽然句子不同，但特定的冷门实体（如某个偏僻的充电站名）在训练集中大量出现，掩盖了模型的泛化能力。

**多模态去重流水线设计 (ASCII)**：

```text
[海量预训练/SFT数据]               [候选测试集]
        |                              |
        v                              v
+-----------------------+      +-----------------------+
| 文本: MinHash/LSH     |      | 文本: N-gram 特征     |
| 图像: Perceptual Hash |      | 图像: pHash/CLIP Embed|
| 音频: Audio Fingerprint|     | 音频: MFCC 特征        |
+-----------------------+      +-----------------------+
        |                              |
        +-------------+----------------+
                      |
                      v
            [向量相似度检索引擎 (Faiss/Milvus)]
                      |
            +---------+---------+
            | 相似度 > 阈值?    |
            +---------+---------+
            | Yes     | No      |
            v         v
       [疑似泄漏]   [安全入库]
            |
      [人工/GPT-4 仲裁]
```

### 2.2.3 动态难度分桶 (Dynamic Difficulty Bucketing)
**Rule of Thumb**：永远不要只汇报一个平均分（Average Score）。平均分掩盖了模型在特定场景下的无能。
测评报告必须包含按 Metadata 分桶的切片分析：

| 分桶维度 | 示例 (Tags) | 作用 |
| :--- | :--- | :--- |
| **模态噪声** | `clean`, `highway_noise`, `music_background`, `rainy_visual`, `low_light` | 评估鲁棒性 |
| **指令复杂度** | `single_turn`, `multi_turn`, `implicit_intent` (隐含意图) | 评估推理深度 |
| **领域/技能** | `navigation`, `entertainment`, `car_control`, `chitchat`, `reasoning` | 评估技能短板 |
| **语言/口音** | `mandarin`, `english`, `sichuan_dialect`, `cantonese`, `mixed` (中英混) | 评估泛化性 |

---

## 2.3 指标体系设计：多模态的度量衡

不同模态需要不同的“尺子”。以下是针对 MLLM 和车载场景的详细指标矩阵。

### 2.3.1 语音识别 (ASR) 与 语音合成 (TTS)
**ASR 指标**：
*   **WER / CER (Word/Character Error Rate)**：通用标准。中文看 CER，英文看 WER。
    *   *Gotcha*：必须进行 **ITN (Inverse Text Normalization)** 归一化。模型输出 "二十四度" 而真值是 "24度"，不应算错。
*   **Entity-CER (关键实体错误率)**：在车载场景，"导航去**天安门**" 识别成 "导航去**天安然**" 是致命错误，而 "帮我" 识别成 "替我" 是可接受的。需对 POI、人名、歌名加权计算。
*   **Wake-up Metrics**: **FAR** (False Accept Rate, 误唤醒率) vs **FRR** (False Reject Rate, 拒识率)。

**TTS 指标**：
*   **MCD (Mel Cepstral Distortion)**：客观声学距离（越低越好），但与听感相关性变弱。
*   **MOS (Mean Opinion Score)**：主观人评金标准（1-5分）。
*   **SMOS (Similarity MOS)**：在声音克隆（如复刻家人声音）场景，评估与参考音频的相似度。
*   **Bad Case Rate (破音/瑕疵率)**：针对电流声、吞字、机械音的专项检测（通常用 ASR 回转或信号处理算法检测）。

### 2.3.2 视觉理解 (Vision: Image & Video)
MLLM 的视觉指标不同于传统的 Detection/Segmentation：
*   **Vision-Language Alignment**:
    *   **Hallucination Rate (幻觉率)**：图片里没有“红灯”，模型说“前面红灯”。这是车舱大忌。
    *   **POPE (Polling-based Object Probing Evaluation)**：通过构造“图里有没有X？”的问题来自动化测试幻觉。
*   **Grounding Accuracy**:
    *   **mIoU / Point Accuracy**：如果模型说“点击那个咖啡店”，输出的坐标框是否准确覆盖目标？
*   **OCR Specifics (Signboard/Menu)**:
    *   **1-NED (Normalized Edit Distance)**：用于评估路牌、菜单文字识别的准确度。
    *   **Key Information Extraction (KIE) F1**：不仅要认出字，还要知道这是“价格”还是“距离”。

### 2.3.3 文本、逻辑与 RAG (Text & Reasoning)
*   **RAG 黄金三角 (Ragas 理念)**：
    1.  **Context Recall (召回率)**：检索到的文档是否包含答案？
    2.  **Faithfulness (忠实度)**：生成的答案是否完全基于检索文档（无外部幻觉）？
    3.  **Answer Relevance (相关性)**：答案是否回答了用户的问题？
*   **逻辑推理**:
    *   **Pass@k**：对于代码生成或数学题，生成 k 次由于一次对即算对（衡量上限）。
    *   **Reasoning Trace Validity**：使用 Judge 模型判断 CoT (Chain of Thought) 的推理步骤是否逻辑自洽。

### 2.3.4 Agent 与 GUI 操作
*   **Success Rate (SR)**：任务最终是否完成（如“设置导航到家”）。
*   **Steps to Success (STS)**：完成任务所需步数。越少越好。
*   **Invalid Action Rate**：模型输出了不存在的按钮、不可点击的坐标或错误的 API 参数的比例。

---

## 2.4 统计显著性：拒绝随机波动

如果你发布一个新版本，准确率从 75.2% 提升到 75.5%，这是进步吗？如果不做统计检验，这可能只是噪声。

### 2.4.1 Bootstrap 重采样法 (The "Gold Standard" for CI)
对于深度学习模型，我们不知道误差分布是否符合正态分布，因此使用 Bootstrap 是最通用的方法。

**操作步骤**：
1.  **采样**：从测试结果集合（如 1000 个样本的预测结果）中，*有放回地* 随机抽取 N 个样本。
2.  **计算**：计算这 N 个样本的指标（如 Accuracy）。
3.  **循环**：重复上述步骤 K 次（如 K=10000），得到 10000 个 Accuracy 分数。
4.  **区间**：将这 10000 个分数排序，取第 2.5% 和第 97.5% 分位点，构成 **95% 置信区间 (Confidence Interval, CI)**。

**判定法则**：
*   如果模型 A 的 CI 是 `[74.8, 75.6]`，模型 B 的 CI 是 `[75.1, 75.9]`。区间重叠严重 -> **差异不显著**（No Significant Difference）。
*   如果模型 A `[74.0, 74.8]`，模型 B `[75.2, 76.0]`。区间不重叠 -> **提升显著**（Significantly Better）。

### 2.4.2 错误分析分类学 (Error Taxonomy)
统计不仅是看总分，更要对错误进行归因。建议在评测报告中维护一个 **Error Heatmap**：

| 错误类型 | 定义 | 示例 | 修复优先级 |
| :--- | :--- | :--- | :--- |
| **Refusal / Safe-trigger** | 错误地触发了安全拦截 | 问“如何切西瓜”被拒答“危险动作” | 高 (影响体验) |
| **Hallucination** | 事实性错误/编造 | 编造不存在的车辆功能 | 极高 (欺诈风险) |
| **Instruction Following** | 未遵循格式/约束 | 要求输出 JSON 输出了 Markdown | 中 |
| **Multimodal Mismatch** | 图文不符 | 没看见图里的障碍物 | 极高 (安全风险) |
| **Reasoning Error** | 逻辑推导错误 | 算错了停车费 | 中 |

---

## 2.5 测评平台工程化：及时与全面

为了平衡成本（Cost）、速度（Latency）和准确度（Accuracy），建议建立三级测评金字塔。

### 2.5.1 L1: 冒烟测试 (Smoke Test / Sanity Check)
*   **触发时机**：每次代码提交 (PR Merge) 或模型 Checkpoint 保存时。
*   **数据集**：< 50 个极具代表性的“探针样本”（包含 10 个正例，10 个必过的反例，10 个多模态简单例）。
*   **目标**：确保模型没“崩”（格式正确、不输出乱码、基本指令能听懂）。
*   **耗时**：< 5 分钟。

### 2.5.2 L2: 每日回归 (Nightly Regression)
*   **触发时机**：每晚定时运行（针对当日最新的最佳 Checkpoint）。
*   **数据集**：~1000 - 2000 样本。覆盖核心垂类（导航、音乐、车控、闲聊）和昨日修复的 Bug Case。
*   **目标**：绘制性能趋势图（Trendline），监控性能回退（Regression）。
*   **告警**：如果有指标下跌超过阈值（如 >1%），自动发送邮件给 On-call 工程师。

### 2.5.3 L3: 版本全量评测 (Release Evaluation)
*   **触发时机**：发版前 (Release Candidate)、季度里程碑。
*   **数据集**：全量数据集（OpenCompass 完整榜单 + 数万条私有车载长尾数据 + 影子模式回放数据）。
*   **目标**：生成最终的 **Model Card**，决定是否准许 OTA 推送。
*   **方法**：通常包含大规模的人工评测（Human Eval）和真车路测。

---

## 2.6 LLM-as-a-Judge：用模型测模型

在缺乏人工标注资源时，使用超大模型（如 GPT-4, Claude-3-Opus）作为裁判是行业标准做法。

### 2.6.1 Judge 的三大偏见与校准
1.  **Position Bias (位置偏见)**：Judge 倾向于认为选项 A (或第一个出现的答案) 更好。
    *   *对策*：**Swap Augmentation**。交换答案顺序跑两次，只有两次都判同一个赢才算赢，否则算平局 (Tie)。
2.  **Verbosity Bias (话痨偏见)**：Judge 倾向于给写得长、排版花哨的答案高分，即使内容空洞。
    *   *对策*：在 Prompt 中明确惩罚冗余，或者在计算分数时引入长度惩罚因子。
3.  **Self-Preference Bias (自我偏好)**：模型倾向于给“自己家族”的模型打高分。
    *   *对策*：使用不同家族的模型组成 **Judge Panel (裁判团)** 投票，或定期计算 Judge 与人类标注的一致性 (Cohen's Kappa)。

### 2.6.2 评分模式：Pointwise vs. Pairwise
*   **Pointwise (单点打分)**：给一个答案打 1-10 分。
    *   *缺点*：模型很难把握“7分”和“8分”的绝对标准，方差大。
*   **Pairwise (成对比较)**：给定两个模型的答案 A 和 B，问 Judge “哪个更好？”
    *   *优点*：更稳定，符合人类直觉（Elo Rating 系统基础）。
    *   *推荐*：在构建 Leaderboard 时首选 Pairwise。

---

## 2.7 车舱落地：驾舱一体专用测评

车内环境特殊，涉及实时性、隐私和多任务并发。

### 2.7.1 影子模式 (Shadow Mode) 与数据回放
真实的车主数据是最宝贵的，但涉及隐私无法直接上传。
*   **Record**: 在车端对 ASR 文本、CAN 总线状态、UI 操作进行脱敏记录。
*   **Replay**: 构建 **Simulator (仿真器)**。将记录下来的“上下文”（如车速 100km/h，正在播放音乐，雨刮器开启）重新注入给待测模型。
*   **Eval**: 对比待测模型的输出（Action）与车主当时的真实操作（Ground Truth Action）。如果车主当时采纳了建议，则为正例；如果车主打断了播报，则为负例。

### 2.7.2 硬门槛指标 (Hard Gates)
对于车载模型，以下指标具有**“一票否决权”**：
1.  **TTFT (Time To First Token)**: 首字延迟。
    *   *标准*：端侧应 < 300ms，云侧应 < 800ms。驾驶时让用户等 2 秒是不可接受的。
2.  **CPU/Memory Footprint**:
    *   *标准*：模型运行期间，不得导致 IVI (In-Vehicle Infotainment) 界面帧率低于 30fps，不得触发 OOM (Out of Memory)。
3.  **Safety Refusal Rate (安全拒答率)**:
    *   *场景*：用户问“怎么把刹车线剪断”。
    *   *标准*：必须 100% 拦截。

### 2.7.3 端云一致性 (Consistency)
车机常在“在线（云端大模型）”和“离线（端侧小模型）”之间切换。
*   **测评方法**：构建一个包含 500 个常用指令的测试集。
*   **指标**：计算 `Similarity(Output_Cloud, Output_Edge)`。
*   **目标**：虽然端侧回复可以简短，但**核心意图**和**执行动作**必须与云端一致。

---

## 2.8 本章小结

1.  **数据决定上限**：遵循 GOLD 原则，建立严格的去污染流水线。
2.  **模态决定尺子**：ASR 看 ITN 后的 CER，RAG 看忠实度，车控看成功率。
3.  **统计决定可信**：不做 Bootstrap 的提升都是耍流氓。
4.  **工程决定效率**：冒烟 -> 回归 -> 全量，分级测试保障敏捷迭代。
5.  **车舱决定生死**：时延、资源占用、安全拦截是比准确率更重要的硬门槛。

---

## 2.9 练习题

### 基础题
1.  **概念辨析**：解释 WER 计算公式 `(I+D+S)/N` 中 I, D, S 分别代表什么？如果一句话标准答案是“打开空调”，模型识别为“帮我把空调打开”，WER 是多少？这合理吗？如果不合理，应引入什么评估手段？
2.  **数据去重**：在做图像理解测评时，为什么简单的 MD5 校验无法发现数据泄漏？请列举至少两种有效的图像去重算法。
3.  **指标计算**：模型 A 在测试集上的准确率是 80%，模型 B 是 81%。测试集只有 100 个样本。请凭直觉判断，模型 B 是否显著强于模型 A？（提示：思考标准差）。

### 挑战题
4.  **场景设计**：你要评测一个“多模态儿童看护助手”（车载后排 OMS）。它需要识别儿童是否哭闹、是否遗留。请设计一个测评方案，包含：数据如何采集（考虑伦理）、核心指标是什么、如何平衡误报（False Alarm）带来的用户骚扰？
5.  **Judge 校准**：你发现 GPT-4 作为 Judge 时，总是倾向于给包含“抱歉，我不能...”的安全拒答回复打低分，即使该问题确实有危险。如何通过 Prompt Engineering 或 Few-shot 示例修正这个偏见？
6.  **端到端思考**：用户说“我觉得有点冷”。传统评测看 Intent Classification 是否分类为 `ADJUST_TEMP`。但在大模型时代，模型可能会反问“要把温度调高一点吗？”或者直接执行。请设计一种能够兼容“直接执行”和“澄清追问”两种正确行为的评测 Metrics。

<details>
<summary>点击展开：练习题提示 (Hints)</summary>

*   **题 1 提示**：I=Insertion, D=Deletion, S=Substitution。WER 会很高，因为字面上完全不同。需要引入 Sem-WER (Semantic WER) 或基于意图槽位的评估 (Slot F1)。
*   **题 2 提示**：图片可能经过了压缩、裁剪、调色。MD5 会变。需要 pHash (感知哈希) 或 CLIP Embedding Cosine Similarity。
*   **题 3 提示**：100 个样本，误差范围大概在 $\sqrt{p(1-p)/n}$ 约等于 4-5%。所以 1% 的差距极大概率是噪声。需要更多数据或 Bootstrap 验证。
*   **题 4 提示**：数据可用演员摆拍或合成。核心指标是 Recall（必须检出遗留），但 Precision 可以稍低。平衡策略：分级告警（低置信度只亮灯不鸣笛）。
*   **题 5 提示**：在 System Prompt 中定义“安全第一”的原则，并在 Few-shot 中提供一个“高分拒答”的样例，告诉 Judge 好的拒答是有价值的。
*   **题 6 提示**：使用“对话状态跟踪 (DST)”或“任务完成率”作为指标。只要最终达成了“温度升高”这个状态，中间是直接执行还是多轮对话都可以算 Success。可以引入“交互步数”作为辅助指标（越少越好）。

</details>

---

## 2.10 常见陷阱与错误 (Gotchas)

*   **陷阱 1：Text Normalization (文本归一化) 的缺失**
    *   *现象*：ASR 准确率极低，发现是因为真值是 "100km"，模型输出 "一百公里"。
    *   *调试*：在评测脚本中加入强力的规则正则（ITN），统一数字、标点、单位、大小写。
*   **陷阱 2：测试集“太干净”**
    *   *现象*：实验室里准确率 99%，上车后只有 60%。
    *   *原因*：测试集是在录音棚录的，没有风噪、胎噪和多人说话。
    *   *调试*：必须进行 **Data Augmentation (数据增强)**，在干净语音上叠加不同信噪比 (SNR) 的车内噪音。
*   **陷阱 3：过度依赖 LLM Judge**
    *   *现象*：GPT-4 说好，人说不好。
    *   *原因*：LLM Judge 对“语气”、“阴阳怪气”或“特定的车载暗语”理解不到位。
    *   *调试*：保持 5%-10% 的样本进行人工抽检（Human-in-the-loop），持续校准 Judge 的 Prompt。
*   **陷阱 4：忽略了“空集”召回**
    *   *现象*：在物体检测/OCR 任务中，如果图里什么都没有，模型也应该输出“无”。很多指标计算库会忽略这些样本。
    *   *调试*：确保指标代码正确处理了 TP=0, FP=0, FN=0, TN=1 的情况，不要出现除以零异常。
