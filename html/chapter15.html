<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 15 章：Agent 能力评测（ReAct、工具调用、长任务、记忆）</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">MLLM 多模理解与生成大模型测评教程（中文）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 1 章：测评总览与能力树</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：数据、指标与统计：从“可比”到“可信”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 3 章：评测平台工程化：统一接口、批量运行、可视化与 CI</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章：ASR 测评（语音识别）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章：TTS 测评（语音合成）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：音频/音乐理解与生成测评 (chapter6.md)</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章：自然图像理解与 OCR（含交通牌、扫码、天气等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 8 章：视频理解（含人流、事件、时序推理、驾驶相关）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章：人头/人脸图像与视频理解（AU、Blendshape、DMS/OMS）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 10 章：GUI 截屏/录屏理解与操作评测（ScreenSuite 等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：文本逻辑性、事实性与低幻觉：客观打分体系</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：RAG 评测：检索与生成的端到端客观评分</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 13 章：文字 + 语音 Role-play 的主观人评（CharacterEval 等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 14 章：代码生成能力评测（作为逻辑性与 Agent 能力 Proxy）</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 15 章：Agent 能力评测（ReAct、工具调用、长任务、记忆）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 16 章：GUI→代码 + 端到端驾舱一体基准（系统集成/回归/反查）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="15-agent-react">第 15 章：Agent 能力评测（ReAct、工具调用、长任务、记忆）</h1>
<h2 id="151">15.1 开篇：从“言语者”到“行动者”</h2>
<p>在 MLLM 的进化树中，如果说 RAG 是为了解决“知之为知之”，那么 <strong>Agent（智能体）</strong> 则是为了解决“行胜于言”。Agent 标志着大模型从被动的文本生成器（Chatbot）转变为能够主动感知环境、规划路径、调用工具并改变世界状态的行动者（Copilot/Action-Bot）。</p>
<p>评测 Agent 与评测对话模型存在本质维度的升维：</p>
<ol>
<li><strong>非确定性环境</strong>：对话通常是静态的，而 Agent 的每一步操作都会改变环境状态（如删除了文件、扣除了余额），导致后续的输入发生变化。</li>
<li><strong>误差累积效应</strong>：在一个包含 10 步操作的长任务中，第 1 步的微小偏差（如选错了日期）可能导致第 10 步的结果完全错误。</li>
<li><strong>闭环验证难题</strong>：评测不仅需要验证模型“说了什么”，更要验证模型“做了什么”以及“结果对不对”。</li>
</ol>
<p>本章将建立一套完整的 Agent 评测体系，涵盖从简单的工具调用（Function Calling）到复杂的 ReAct 推理循环，再到长程记忆保持的系统性评估。</p>
<hr />
<h2 id="152-agent">15.2 Agent 核心架构与评测切面</h2>
<p>目前主流 Agent 多遵循 <strong>ReAct (Reasoning + Acting)</strong> 或 <strong>Plan-and-Solve</strong> 范式。我们需要对 Agent 运行时的每个环节进行切片评测。</p>
<h3 id="1521-react">15.2.1 ReAct 循环的解剖</h3>
<p>Agent 的运行是一个由 <strong>[Thought] -&gt; [Action] -&gt; [Observation]</strong> 构成的无限循环，直到任务结束。</p>
<p><strong>ASCII 示意图：ReAct 循环中的评测埋点</strong></p>
<div class="codehilite"><pre><span></span><code>User Goal: &quot;帮我把 download 文件夹里所有大于 10MB 的 PDF 移动到 archive 目录。&quot;

      +-------------------------------------------------------------+
      |                        MLLM Agent                           |

      |                        MLLM Agent                           |
      |                                                             |
(T1)  | [Thought]:  需要先列出 download 目录文件，筛选大小和后缀。  | &lt;--- 评测切面 A: 规划能力
      |             (Plan: List -&gt; Filter -&gt; Move)                  |      (是否正确分解了子任务？)
      |                                                             |
(A1)  | [Action]:   os.list_dir(path=&quot;./download&quot;)                  | &lt;--- 评测切面 B: 工具选择与参数

      +-----------------------------+-------------------------------+      (Schema 是否符合？路径对吗？)
                                    | Call Tool
                                    v
      +-------------------------------------------------------------+
      |                 Environment (Mock/Sandbox)                  |

      |                 Environment (Mock/Sandbox)                  |
      |                                                             |
(O1)  | [Observation]: [&quot;a.pdf (2MB)&quot;, &quot;b.pdf (15MB)&quot;, &quot;img.png&quot;]   | &lt;--- 评测切面 C: 环境仿真度

      +-----------------------------+-------------------------------+      (Mock 数据是否足以触发下一步？)
                                    | Return Result
                                    v
      +-------------------------------------------------------------+
      |                        MLLM Agent                           |

      |                        MLLM Agent                           |
      |                                                             |
(T2)  | [Thought]:  发现 b.pdf 是目标文件。a.pdf太小，img不是pdf。  | &lt;--- 评测切面 D: 状态追踪与推理
      |             现在移动 b.pdf。                                |      (是否正确理解了 Observation？)
      |                                                             |
(A2)  | [Action]:   os.move(src=&quot;./download/b.pdf&quot;, dst=&quot;./archive&quot;)|

      +-------------------------------------------------------------+
                                    |
                  (循环直至输出 Finish 或达到 Max Steps)
</code></pre></div>

<h3 id="1522">15.2.2 三大核心能力维度</h3>
<ol>
<li>
<p><strong>工具使用 (Tool Use / Function Calling)</strong></p>
<ul>
<li><strong>检索 (Retrieval)</strong>：在成百上千个工具（API 库）中，能否召回正确的那个？（例如：不要在需要 <code>math.sqrt</code> 时调用 <code>weather.get</code>）。</li>
<li><strong>参数填充 (Slot Filling)</strong>：能否从复杂的上下文或模糊的用户指令中提取出精确参数？（例如：将“下周三”转换为 <code>2025-10-15</code>）。</li>
<li><strong>容错 (Exception Handling)</strong>：当工具返回报错（如 <code>ConnectionError</code> 或 <code>InvalidParam</code>）时，Agent 是崩溃、胡言乱语，还是尝试自我修正参数重试？</li>
</ul>
</li>
<li>
<p><strong>规划与逻辑 (Planning &amp; Reasoning)</strong></p>
<ul>
<li><strong>任务分解</strong>：将复杂目标拆解为线性或并行的子步骤。</li>
<li><strong>依赖管理</strong>：识别步骤间的依赖关系（必须先 <code>get_user_id</code> 才能 <code>query_balance</code>）。</li>
<li><strong>反思 (Reflection)</strong>：在多次尝试失败后，能否改变策略？</li>
</ul>
</li>
<li>
<p><strong>长程记忆 (Long-term Memory)</strong></p>
<ul>
<li><strong>状态保持</strong>：在第 20 轮交互时，是否还记得第 1 轮设定的 <code>verbose=True</code> 全局约束。</li>
<li><strong>跨会话记忆</strong>：能否利用昨天的对话历史来辅助今天的决策（如用户偏好）。</li>
</ul>
</li>
</ol>
<hr />
<h2 id="153-mock-sandbox">15.3 评测环境工程：Mock 与 Sandbox</h2>
<p><strong>Rule of Thumb</strong>：<strong>永远不要在不可控的真实环境中评测 Agent 指标。</strong> 真实环境的网络波动、API 变动、数据即时性会导致评测结果无法跨版本对比（Non-deterministic）。</p>
<p>我们需要构建分级的评测环境：</p>
<h3 id="1531-level-1-mock-stateless-mock">15.3.1 Level 1: 静态 Mock (Stateless Mock)</h3>
<p>适用于<strong>工具调用准确率</strong>的单元测试。</p>
<ul>
<li><strong>原理</strong>：预定义好 <code>(Input Prompt, Expected Tool Call)</code> 对。</li>
<li><strong>实现</strong>：不执行真正的工具，只检查 LLM 输出的文本（Action 字符串）。</li>
<li><strong>优点</strong>：速度极快，成本低，适合 CI 冒烟测试。</li>
<li><strong>局限</strong>：无法测试多步依赖和错误恢复。</li>
</ul>
<h3 id="1532-level-2-mock-stateful-mock">15.3.2 Level 2: 状态机 Mock (Stateful Mock)</h3>
<p>适用于<strong>多轮 ReAct 流程</strong>评测。</p>
<ul>
<li><strong>原理</strong>：维护一个虚拟的状态字典（State Dict）。</li>
<li><strong>示例</strong>：<ul>
<li>初始状态：<code>{"files": ["report.pdf"], "trash": []}</code></li>
<li>Action: <code>delete("report.pdf")</code></li>
<li>Mock Server 逻辑：更新状态为 <code>{"files": [], "trash": ["report.pdf"]}</code>，并返回 <code>Success</code>。</li>
</ul>
</li>
<li><strong>优点</strong>：支持多步逻辑验证（如“先查后删”），且完全确定性。</li>
<li><strong>场景</strong>：数据库操作、文件系统操作、购物车流程。</li>
</ul>
<h3 id="1533-level-3-sandboxed-container">15.3.3 Level 3: 沙箱容器 (Sandboxed Container)</h3>
<p>适用于<strong>代码生成与执行</strong>（Code Agent）或<strong>复杂 GUI 操作</strong>。</p>
<ul>
<li><strong>原理</strong>：为每个评测任务启动一个 Docker 容器或虚拟机。</li>
<li><strong>实现</strong>：<ul>
<li>使用 OpenDevin 或 E2B 等框架。</li>
<li>环境快照（Snapshot）：每次任务开始前重置到纯净镜像。</li>
<li>网络隔离：限制只能访问 Mock 的 API Server，防止模型通过公网搜索答案（Leaking）。</li>
</ul>
</li>
<li><strong>成本</strong>：极高，通常用于 Nightly 或 Weekly 深度评测。</li>
</ul>
<hr />
<h2 id="154">15.4 指标体系详解</h2>
<h3 id="1541-outcome-metrics">15.4.1 结果质量指标 (Outcome Metrics)</h3>
<ol>
<li><strong>任务成功率 (Success Rate, SR)</strong><ul>
<li><strong>定义</strong>：任务结束时，环境状态是否符合预期？</li>
<li><strong>判定方法</strong>：<ul>
<li><em>确定性判定</em>：检查数据库字段、文件是否存在、API 返回值。</li>
<li><em>LLM-based Judge</em>：对于开放性任务（如“写一个关于某事的总结”），将轨迹（Trajectory）和结果喂给 GPT-4 进行打分。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Pass@K</strong><ul>
<li>给模型 K 次独立尝试的机会（每次从头开始，Temperatue &gt; 0），只要有一次成功即算通过。用于衡量模型的潜能上限。</li>
</ul>
</li>
</ol>
<h3 id="1542-process-metrics">15.4.2 过程质量指标 (Process Metrics)</h3>
<ol>
<li><strong>轨迹效率 (Trajectory Efficiency)</strong><ul>
<li>$$ \text{Efficiency} = \frac{\text{Steps}_{\text{optimal}}}{\text{Steps}_{\text{actual}}} $$</li>
<li>如果标准做法是 3 步，模型走了 10 步才完成，说明效率极低，虽然 SR=100%，但在车载等场景不可用。</li>
</ul>
</li>
<li><strong>幻觉工具率 (Tool Hallucination Rate)</strong><ul>
<li>调用了不存在的函数，或捏造了不存在的参数名的比例。</li>
</ul>
</li>
<li><strong>格式依从度 (Schema Compliance)</strong><ul>
<li>输出的 JSON/XML 能够被标准 Parser 解析成功的比例。</li>
</ul>
</li>
</ol>
<h3 id="1543">15.4.3 记忆与长上下文指标</h3>
<ol>
<li><strong>信息检索准确率 (Retrieval Accuracy in Context)</strong><ul>
<li>Needle-in-a-Haystack 的变体：在 100 轮对话历史中插入一条 Action 指令（“顺便把日志级别设为 Debug”），看最终执行时是否生效。</li>
</ul>
</li>
<li><strong>状态漂移 (State Drift)</strong><ul>
<li>在长任务中，模型是否会忘记之前的约束？（例如：用户要求“全程只用英文”，第 15 步后模型突然切回中文）。</li>
</ul>
</li>
</ol>
<hr />
<h2 id="155">15.5 现有开源基准与选型建议</h2>
<p>| 基准名称 | 适用场景 | 特点 | 推荐指数 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">基准名称</th>
<th style="text-align: left;">适用场景</th>
<th style="text-align: left;">特点</th>
<th style="text-align: left;">推荐指数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>AgentBench</strong></td>
<td style="text-align: left;">综合能力</td>
<td style="text-align: left;">包含 OS、DB、KG、卡牌游戏等 8 个环境，覆盖面广</td>
<td style="text-align: left;">⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ToolBench</strong></td>
<td style="text-align: left;">工具调用</td>
<td style="text-align: left;">侧重指令微调与 API 泛化，包含大量真实 API 的 Mock</td>
<td style="text-align: left;">⭐⭐⭐⭐</td>
</tr>
<tr>
<td style="text-align: left;"><strong>GAIA</strong></td>
<td style="text-align: left;">困难推理</td>
<td style="text-align: left;">任务看似简单但需要复杂多步推理，目前模型普遍低分，适合测上限</td>
<td style="text-align: left;">⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td style="text-align: left;"><strong>SWE-bench</strong></td>
<td style="text-align: left;">代码工程</td>
<td style="text-align: left;">解决真实的 GitHub Issue，难度极高，适合 Coding Agent</td>
<td style="text-align: left;">⭐⭐⭐</td>
</tr>
<tr>
<td style="text-align: left;"><strong>AppAgent</strong></td>
<td style="text-align: left;">移动端操作</td>
<td style="text-align: left;">结合多模态（看图操作手机），适合车机/手机助手评测</td>
<td style="text-align: left;">⭐⭐⭐⭐</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="156">15.6 本章小结</h2>
<ol>
<li><strong>评测核心</strong>：Agent 评测关注的是“状态改变的正确性”，而不仅仅是文本输出的语义相似度。</li>
<li><strong>架构循环</strong>：必须对 <strong>Thought (规划)</strong>、<strong>Action (执行)</strong>、<strong>Observation (理解)</strong> 三个环节分别埋点，才能定位是“想错了”还是“手滑了”。</li>
<li><strong>环境分级</strong>：从静态 Mock 到动态 Sandbox，环境越真实，评测成本越高，确定性越低。建议 CI 阶段用 Stateless Mock，版本验收用 Stateful Sandbox。</li>
<li><strong>安全底线</strong>：Agent 具备破坏力。评测集中必须包含“诱导删除系统文件”、“诱导转账”等防御性测试用例。</li>
</ol>
<hr />
<h2 id="157">15.7 练习题</h2>
<h3 id="_1">基础题</h3>
<ol>
<li><strong>环境构建</strong>：你需要评测一个“订机票 Agent”。请设计一个 <strong>Stateful Mock</strong> 环境。<ul>
<li><em>Hint</em>：你需要维护一个包含“航班余票”、“用户余额”、“订单列表”的虚拟数据库。当 <code>book_ticket</code> 被调用时，余票减 1，余额减少，订单增加。</li>
</ul>
</li>
<li><strong>指标计算</strong>：模型 A 完成任务用了 5 步，成功率 90%；模型 B 用了 3 步，成功率 85%。在<strong>车载语音助手</strong>场景下，你倾向于选择哪个模型？为什么？<ul>
<li><em>Hint</em>：考虑用户对延迟的容忍度（Time-to-Action）以及语音交互的冗长感。</li>
</ul>
</li>
<li><strong>Schema 验证</strong>：给定工具 <code>search(query: str, limit: int = 10)</code>。模型输出 <code>search(keywords="apple", max_num="five")</code>。请指出其中的 3 个错误。<ul>
<li><em>Hint</em>：参数名错误、参数值类型错误、多余参数/缺失参数。</li>
</ul>
</li>
</ol>
<h3 id="_2">挑战题</h3>
<ol start="4">
<li><strong>死循环检测算法</strong>：设计一个算法，能够在评测运行时自动中断陷入死循环的 Agent，并给出“Loop Detected”的错误码。<ul>
<li><em>Hint</em>：简单的字符串匹配不够。考虑 Action + Arguments 的哈希值序列，寻找重复子串（如 A-&gt;B-&gt;A-&gt;B）。</li>
</ul>
</li>
<li><strong>反思能力评测</strong>：设计一个测试用例，强制 Agent 第一次尝试失败，考察其自我修正能力。<ul>
<li><em>Hint</em>：Mock 环境在第一次调用正确参数时故意返回“System Busy”或“Unknown Error”，看 Agent 是复读还是重试/查文档。</li>
</ul>
</li>
<li><strong>思考题</strong>：在 RAG + Agent 混合场景中（先查手册再操作），如何通过指标区分是“知识检索错误”还是“操作逻辑错误”？<ul>
<li><em>Hint</em>：需要中间指标 Context Recall（检索到的内容是否包含答案）作为分界线。</li>
</ul>
</li>
</ol>
<details>
<summary><strong>点击查看参考答案</strong></summary>
<ul>
<li><strong>题 1</strong>：Mock Class 需包含 <code>__init__</code> 初始化状态，<code>book()</code> 方法需包含 <code>if balance &lt; price: return Error</code> 等逻辑。</li>
<li><strong>题 2</strong>：车载场景通常倾向于 <strong>模型 B</strong>（效率优先），前提是 85% 的成功率在可接受范围内，或者有良好的失败兜底（Ask for clarification）。多 2 步的交互在语音场景下会增加 10-20 秒的时间，体验极差。</li>
<li><strong>题 3</strong>：1. 参数名 <code>keywords</code> 错误（应为 <code>query</code>）；2. 参数名 <code>max_num</code> 错误（应为 <code>limit</code>）；3. 参数值 <code>"five"</code> 是字符串（应为 <code>int</code> 如 <code>5</code>）。</li>
<li><strong>题 4</strong>：维护一个滑动窗口或 Hash Set。<code>history = []</code>. 每步 <code>curr_hash = hash(tool_name + sorted_args)</code>. 如果 <code>curr_hash</code> 连续 N 次出现在 <code>history</code> 的尾部，或呈现周期性，则判定 Loop。</li>
<li><strong>题 5</strong>：场景：查询天气。Step 1: Agent 调用 <code>get_weather(city="Beijing")</code>。Mock 返回：<code>Error: City name must be in Pinyin with strictly lowercase</code>。期望 Step 2: Agent 输出 <code>get_weather(city="beijing")</code>。</li>
<li><strong>题 6</strong>：计算 $P(Success | Context_Correct)$ 和 $P(Success | Context_Wrong)$。如果前者很高但后者很低，说明 Agent 能力没问题，是 RAG 拖后腿。如果两者都低，说明 Agent 执行能力差。</li>
</ul>
</details>
<hr />
<h2 id="158-gotchas">15.8 常见陷阱与错误 (Gotchas)</h2>
<ol>
<li>
<p><strong>Mock 的数据泄漏 (Data Contamination)</strong></p>
<ul>
<li><em>陷阱</em>：Mock 的天气接口总是返回“25度”。模型经过微调后，记住了“天气=25度”，不再调用工具而是直接回答。</li>
<li><em>对策</em>：Mock 数据应在运行时随机生成（如随机温度），强制模型必须执行 <code>Observation</code> 读取步骤。</li>
</ul>
</li>
<li>
<p><strong>解析器的“过度溺爱” (Over-lenient Parsing)</strong></p>
<ul>
<li><em>陷阱</em>：评测脚本里的 Regex 写得太强，帮模型自动修复了缺少的引号、逗号。</li>
<li><em>后果</em>：评测分很高，上线接真实 API 时全挂。</li>
<li><em>对策</em>：评测阶段应使用与生产环境一致的 Strict JSON Parser。</li>
</ul>
</li>
<li>
<p><strong>忽略了“什么都不做”的正确性</strong></p>
<ul>
<li><em>陷阱</em>：有些任务需要 Agent 判定“无法完成”并拒答。如果评测只包含可完成的任务，模型会变成“乱操作狂”。</li>
<li><em>对策</em>：测试集中必须包含 10%-20% 的不可完成任务（Unsolvable Tasks），预期结果是 Agent 输出“我无法完成，因为...”。</li>
</ul>
</li>
</ol>
<hr />
<h2 id="159-ui">15.9 车舱落地：驾舱一体（对话→工具→UI→导航的闭环）</h2>
<p>车载 Agent 是多模态、实时、安全敏感的综合体。</p>
<h3 id="1591">15.9.1 端到端链路评测</h3>
<p>在车机中，Agent 往往不仅调用 API，还联动 UI。</p>
<ul>
<li><strong>场景</strong>：“帮我找一家附近评分最高的川菜馆，并发给微信上的老婆。”</li>
<li><strong>工具链</strong>：<code>POI Search (Map)</code> -&gt; <code>Filter/Sort</code> -&gt; <code>WeChat API</code>。</li>
<li><strong>评测点</strong>：<ul>
<li><strong>Slot Carry-over</strong>：地图搜到的餐厅名字/地址，是否精准透传给了微信发送接口？（常见错误：发过去的信息是“这家店”而不是具体的店名）。</li>
<li><strong>多模态反馈</strong>：Agent 操作成功后，是否在屏幕上弹出了 Toast 或 Card？评测需要结合 <strong>GUI 截图理解</strong>（第 10 章）来验证 UI 反馈的正确性。</li>
</ul>
</li>
</ul>
<h3 id="1592-shadow-mode">15.9.2 影子模式 (Shadow Mode) 评测</h3>
<p>由于无法在真实驾驶中让测试版模型随意操作车辆，推荐使用“影子模式”。</p>
<ul>
<li><strong>实施</strong>：在路测车上，记录驾驶员的真实语音指令和随后的真实操作（如手点屏幕导航）。</li>
<li><strong>回放</strong>：在云端/离线环境中，将同样的语音输入给 Agent。</li>
<li><strong>对比</strong>：比较 Agent 生成的 Action 序列与驾驶员真实操作（Ground Truth）的重合度。<ul>
<li><em>注意</em>：Agent 可能有比人更好的解法，因此不匹配不一定代表错，需人工仲裁或规则校验。</li>
</ul>
</li>
</ul>
<h3 id="1593-hardware-in-the-loop-hil">15.9.3 硬件在环 (Hardware-In-the-Loop, HIL)</h3>
<p>车载 Agent 运行在算力受限的 SoC（如高通 8295/8255）上。</p>
<ul>
<li><strong>资源抢占评测</strong>：当 Agent 进行复杂的 ReAct 推理时，是否导致导航掉帧？是否导致 DMS 监控延迟？</li>
<li><strong>指标</strong>：<ul>
<li><strong>TTFT (Time to First Token)</strong>：首字延迟。</li>
<li><strong>Total Latency</strong>：完成任务的总耗时。</li>
<li><strong>CPU/NPU Usage</strong>：推理过程中的峰值功耗。</li>
</ul>
</li>
</ul>
<h3 id="1594-safety-guardrails">15.9.4 安全护栏 (Safety Guardrails)</h3>
<ul>
<li><strong>权限隔离</strong>：评测 Agent 是否能在驾驶状态下<strong>拒绝</strong>高风险指令（如“播放视频”、“打开引擎盖”）。</li>
<li><strong>二次确认</strong>：对于敏感操作（如“呼叫 110”、“导航去 2000公里外”），Agent 必须触发 Confirm UI 或语音确认。评测标准是：<em>没有 Confirm 步骤直接调 API 判为 FAIL</em>。</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter14.html" class="nav-link prev">← 第 14 章：代码生成能力评测（作为逻辑性与 Agent 能力 Proxy）</a><a href="chapter16.html" class="nav-link next">第 16 章：GUI→代码 + 端到端驾舱一体基准（系统集成/回归/反查） →</a></nav>
        </main>
    </div>
</body>
</html>