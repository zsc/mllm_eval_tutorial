<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 3 章：评测平台工程化：统一接口、批量运行、可视化与 CI</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">MLLM 多模理解与生成大模型测评教程（中文）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 1 章：测评总览与能力树</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：数据、指标与统计：从“可比”到“可信”</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 3 章：评测平台工程化：统一接口、批量运行、可视化与 CI</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章：ASR 测评（语音识别）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章：TTS 测评（语音合成）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：音频/音乐理解与生成测评 (chapter6.md)</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章：自然图像理解与 OCR（含交通牌、扫码、天气等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 8 章：视频理解（含人流、事件、时序推理、驾驶相关）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章：人头/人脸图像与视频理解（AU、Blendshape、DMS/OMS）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 10 章：GUI 截屏/录屏理解与操作评测（ScreenSuite 等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：文本逻辑性、事实性与低幻觉：客观打分体系</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：RAG 评测：检索与生成的端到端客观评分</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 13 章：文字 + 语音 Role-play 的主观人评（CharacterEval 等）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="3-ci">第 3 章：评测平台工程化：统一接口、批量运行、可视化与 CI</h1>
<h2 id="1">1. 开篇与学习目标</h2>
<p>在单模态 NLP 时代，跑几个 benchmark 可能只需要一个 Jupyter Notebook。但在 MLLM（多模态大模型）时代，输入涉及 4K 视频流、长音频、高分辨率文档图像，输出涉及多轮对话、工具调用（Function Call）和多媒体生成。数据量的爆炸和交互的复杂性，使得<strong>评测本身如果不工程化，将成为模型迭代最大的瓶颈。</strong></p>
<p>一个优秀的评测平台不仅仅是“跑分工具”，它是<strong>模型能力的体检中心</strong>和<strong>产品发布的守门员</strong>。本章的核心目标是构建一个<strong>模块化、可扩展、抗脆弱</strong>的生产级评测基础设施。</p>
<p><strong>本章学习目标</strong>：</p>
<ol>
<li><strong>架构设计模式</strong>：掌握 Configuration-as-Code 和 Pipeline 模式，实现数据、模型、评测逻辑的彻底解耦。</li>
<li><strong>高吞吐数据管线</strong>：深入理解多模态数据的 ETL（提取、转换、加载）流程，处理视频解码、音频流式加载与缓存策略。</li>
<li><strong>运行器与容错</strong>：设计支持断点续跑、并发控制、分布式调度的健壮 Runner。</li>
<li><strong>CI/CD 流水线</strong>：建立从 PR 冒烟到版本门禁的分级测试体系，设定 Latency 和 Cost 预算。</li>
<li><strong>驾舱一体化仿真</strong>：在离线环境中构建“虚拟车辆”，Mock 硬件信号与车控 API，实现端到端闭环评测。</li>
</ol>
<hr />
<h2 id="2">2. 评测平台架构体系</h2>
<p>一个成熟的 MLLM 评测平台（Evaluation Harness）应遵循 <strong>“配置驱动 (Config-Driven)”</strong> 和 <strong>“组件插件化 (Plugin-Based)”</strong> 的原则。</p>
<h3 id="21-ascii">2.1 顶层设计与 ASCII 视图</h3>
<p>平台的核心思想是：<strong>将变化最快的部分（模型接口、数据集）与相对稳定的部分（调度逻辑、打分算法）分离。</strong></p>
<div class="codehilite"><pre><span></span><code>[用户输入] (Config YAML)
     │
     ▼
[注册中心 (Registry)] &lt;--- 动态加载 Dataset / Model / Scorer 类
     │
     ▼
[运行器 (Runner)] -------------------------------------------+
│  1. Data Loader (ETL: 解码/采样/缓存)                       |
│  2. Prompt Builder (模版组装/Few-shot注入)                  |
│  3. Model Adapter (异构接口统一/重试/限流)                   |
│  4. Response Dumper (实时落盘 jsonl)                        |
+------------------------------------------------------------+
     │
     ▼
[后处理流水线 (Post-processing Pipeline)]
│  1. Extractor (正则/解析器: 从输出提取答案)
│  2. Judge/Scorer (计算指标: WER/Rouge/GPT-4-Score)
│  3. Analyzer (聚合分析: 失败聚类/对比Diff)
+------------------------------------------------------------+
     │
     ▼
[可视化报告 (Dashboard)] (HTML/WandB)
</code></pre></div>

<h3 id="22-repository-structure">2.2 仓库结构约定 (Repository Structure)</h3>
<p>推荐采用类似 OpenCompass 或 Detectron2 的配置继承机制，以支持大量的消融实验。</p>
<div class="codehilite"><pre><span></span><code>mllm-eval-platform/
├── configs/                  # [配置中心]
│   ├── _base_/               # 基础配置 (继承用)
│   │   ├── datasets/         # 数据集定义 (path, reader_cfg)
│   │   └── models/           # 模型参数 (temperature, max_tokens)
│   ├── regression/           # 回归任务集 (e.g., nightly_v1.py)
│   └── ablation/             # 消融实验集 (e.g., context_len_test.py)
├── core/
│   ├── adapters/             # [模型适配] HTTP/gRPC/Local Wrapper
│   ├── data/                 # [数据管线] Transform, CollateFn
│   ├── evaluators/           # [打分器] Metric calculators
│   └── hooks/                # [钩子] Callbacks (logging, visualization)
├── tools/
│   ├── analysis/             # 错误分析工具, 训练数据查重
│   └── mock/                 # [车端模拟] Vehicle Signal Mocker
├── work_dirs/                # [产出物]
│   └── 20250101_model_v2/
│       ├── config_dump.yaml  # 复现快照
│       ├── predictions.jsonl # 中间结果 (含 prompt, raw output)
│       ├── results.json      # 最终分数
│       └── failure_cases/    # 渲染后的坏例页面
└── tests/                    # 单元测试
</code></pre></div>

<hr />
<h2 id="3">3. 关键组件工程化详解</h2>
<h3 id="31-model-adapter">3.1 模型适配层 (Model Adapter)：统一异构接口</h3>
<p>MLLM 的后端千奇百怪（HF Pipeline, vLLM, TensorRT-LLM, 私有云 API）。Adapter 必须屏蔽这些差异，向 Runner 暴露<strong>统一的多模态消息协议</strong>。</p>
<p><strong>Rule of Thumb</strong>: 内部协议应向 OpenAI Chat 格式靠拢，但必须扩展对本地媒体文件的支持。</p>
<ul>
<li><strong>输入标准化</strong>：</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="c1"># 内部统一表示 (Intermediate Representation)</span>
<span class="n">message</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;/local/path/to/img.jpg&quot;</span><span class="p">},</span> <span class="c1"># 或 base64, 或 s3_url</span>
        <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="s2">&quot;/local/path/to/speech.wav&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;这段语音里的用户想去哪里？&quot;</span><span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><strong>参数透传</strong>：Adapter 应支持 <code>generation_kwargs</code> 的透传，以便控制 <code>temperature</code>, <code>top_p</code>, <code>repetition_penalty</code>。</li>
<li><strong>异常处理</strong>：必须在 Adapter 层处理 <code>ModelOverloaded</code>, <code>RateLimitError</code>，实现指数退避重试（Exponential Backoff）。</li>
</ul>
<h3 id="32-data-pipeline-io-tensor">3.2 数据管线 (Data Pipeline)：从 I/O 到 Tensor</h3>
<p>这是 MLLM 评测中最重、最易出错的环节。</p>
<ul>
<li><strong>视频解码策略 (Video Decoding)</strong>：<ul>
<li><em>问题</em>：在线解码 4K 视频极其消耗 CPU，导致 GPU 等待（Starvation）。</li>
<li><em>优化</em>：<ol>
<li><strong>离线预处理</strong>：对于固定的数据集，预先抽取关键帧（FPS=1 或 场景切变点）存为 JPG。</li>
<li><strong>缓存机制</strong>：使用 LRU Cache 缓存最近解码的帧或 Audio Mel-Spectrogram。</li>
<li><strong>多进程 Loader</strong>：PyTorch <code>DataLoader</code> 的 <code>num_workers &gt; 0</code> 是必须的。</li>
</ol>
</li>
</ul>
</li>
<li><strong>确定性 (Determinism)</strong>：<ul>
<li>评测中<strong>严禁</strong>使用随机增强（Random Flip, Color Jitter）。</li>
<li>Resize 和 Crop 必须中心对齐（Center Crop）。</li>
<li>音频重采样（Resample）必须指定固定的算法和 backend (e.g., <code>sox</code> vs <code>ffmpeg</code>)，微小的差异可能导致 ASR WER 波动。</li>
</ul>
</li>
<li><strong>动态 Batching</strong>：<ul>
<li>纯文本容易 batch，但不同长度的视频/音频混合 batch 极难。</li>
<li><em>策略</em>：对于多模态任务，推荐 <strong>Batch Size = 1</strong> 并发执行（通过多线程/多进程请求 API），或者按模态+长度分桶（Bucketing）后再 Batch。</li>
</ul>
</li>
</ul>
<h3 id="33-runner">3.3 运行器 (Runner) 与 状态管理</h3>
<ul>
<li><strong>断点续跑 (Resume Capability)</strong>：<ul>
<li><strong>原则</strong>：评测过程随时可能因为 OOM 或网络波动崩溃。</li>
<li><strong>实现</strong>：Runner 启动时，先扫描 output 目录下的 <code>results.jsonl</code>，读取已存在的 <code>sample_id</code> 加载到 Set 中。数据迭代器自动 <code>continue</code> 跳过这些 ID。</li>
<li><strong>原子写入</strong>：确保每一条结果写入是原子的（flush），避免 json 截断。</li>
</ul>
</li>
<li><strong>并发控制 (Concurrency Throttling)</strong>：<ul>
<li>配合 Token Bucket 算法控制每分钟请求数 (RPM) 和 Token 数 (TPM)，防止被云端 API 封禁或把自建推理服务打挂。</li>
</ul>
</li>
</ul>
<h3 id="34-scorer">3.4 打分器 (Scorer)：解耦与多级评测</h3>
<p>打分不应与推理耦合。推荐采用 <strong>Inference -&gt; Dump -&gt; Judge</strong> 的两阶段模式。</p>
<ol>
<li><strong>客观提取器 (Extractor)</strong>：<ul>
<li>针对选择题，使用增强型正则（Regex）提取选项。处理 "The answer is A" 或 "A matches the image" 等变体。</li>
<li>针对 JSON 输出，使用宽松的 JSON Parser（如 <code>json5</code> 或大模型修复 parser）。</li>
</ul>
</li>
<li><strong>相似度计算器 (Metric Calculator)</strong>：<ul>
<li>文本：BLEU, ROUGE-L, METEOR.</li>
<li>代码：Pass@k (需沙箱执行).</li>
<li>向量距离：Embedding Cosine Similarity (语义相似度).</li>
</ul>
</li>
<li><strong>LLM-as-a-Judge</strong>：<ul>
<li>使用 GPT-4 或专门微调的 Critic 模型对开放性问题打分（1-10分）。</li>
<li><strong>Gotcha</strong>: Judge 模型自身存在 bias（偏好长回复）。需要校准（Calibration）或使用 Pairwise 比较（Win/Tie/Loss）。</li>
</ul>
</li>
</ol>
<h3 id="35">3.5 报告与可视化系统</h3>
<p>一份 100MB 的日志文件没人看，需要可视化的仪表盘。</p>
<ul>
<li><strong>动态仪表盘</strong>：集成 Streamlit 或 WandB。</li>
<li><strong>Diff View (关键功能)</strong>：<ul>
<li>左侧：Baseline 模型输出。</li>
<li>右侧：当前模型输出。</li>
<li>高亮：语义差异部分。</li>
<li><em>用途</em>：用于 RAG 评测，快速判断新模型是否引入了幻觉。</li>
</ul>
</li>
<li><strong>失败聚类 (Failure Clustering)</strong>：<ul>
<li>自动将 Error Case 按 tag 归类：<code>[OCR_Miss]</code>, <code>[Logic_Error]</code>, <code>[Safety_Trigger]</code>.</li>
</ul>
</li>
</ul>
<hr />
<h2 id="4-cicd">4. CI/CD 集成策略：将评测融入研发心跳</h2>
<p>不要等到发版前才评测。</p>
<h3 id="41">4.1 分级测试金字塔</h3>
<p>| 级别 | 触发时机 | 数据规模 | 核心指标 | 耗时预算 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">级别</th>
<th style="text-align: left;">触发时机</th>
<th style="text-align: left;">数据规模</th>
<th style="text-align: left;">核心指标</th>
<th style="text-align: left;">耗时预算</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>L0: Smoke (冒烟)</strong></td>
<td style="text-align: left;">每次 PR 提交</td>
<td style="text-align: left;">极小 (每类任务 5-10 例)</td>
<td style="text-align: left;">格式正确性, 无 Crash</td>
<td style="text-align: left;">&lt; 5 min</td>
</tr>
<tr>
<td style="text-align: left;"><strong>L1: Nightly (回归)</strong></td>
<td style="text-align: left;">每日凌晨</td>
<td style="text-align: left;">中等 (核心集 10% 采样)</td>
<td style="text-align: left;">WER, Accuracy, RAG召回率</td>
<td style="text-align: left;">&lt; 2 hrs</td>
</tr>
<tr>
<td style="text-align: left;"><strong>L2: Weekly/Release</strong></td>
<td style="text-align: left;">发版/周维度</td>
<td style="text-align: left;">全量 (所有 Benchmark)</td>
<td style="text-align: left;">全项指标 + 竞品对比</td>
<td style="text-align: left;">&gt; 24 hrs</td>
</tr>
</tbody>
</table>
<h3 id="42-quality-gates">4.2 质量门禁 (Quality Gates)</h3>
<p>在 CI Pipeline 中设置硬性拦截规则：</p>
<ol>
<li><strong>功能回退拦截</strong>：核心任务（如导航指令解析）准确率下降幅度不得超过 1%。</li>
<li><strong>时延拦截</strong>：TTFT (Time To First Token) 95分位值不得增加超过 50ms。</li>
<li><strong>安全拦截</strong>：Prompt Injection 攻击成功率必须为 0%。</li>
</ol>
<hr />
<h2 id="5">5. 训练数据问题反查工作流</h2>
<p>当评测分数异常高（疑似泄漏）或由于“不知道”而回答错误时，需要反查训练数据。</p>
<p><strong>工程实现</strong>：</p>
<ol>
<li><strong>索引构建</strong>：使用向量数据库（Milvus/FAISS）对所有训练数据（图/文）建立索引。</li>
<li><strong>即时检索</strong>：评测报告页面增加 "Check Training Data" 按钮。<ul>
<li>点击后，Embedding 当前评测样本，在向量库中检索 Top-K 相似训练样本。</li>
</ul>
</li>
<li><strong>污染判定</strong>：计算 n-gram 重叠率或图像指纹相似度。如果重叠率 &gt; 0.8，标记为 "Contaminated"，该分数在最终报告中应剔除或降权。</li>
</ol>
<hr />
<h2 id="6">6. 车舱落地：驾舱一体工程化专项</h2>
<p>车载环境的特殊性在于：<strong>强实时性、硬件依赖、端云协同</strong>。通用评测框架无法直接覆盖，需要定制。</p>
<h3 id="61-mock-vehicle-environment">6.1 虚拟车身环境 (Mock Vehicle Environment)</h3>
<p>在离线评测 Runner 中，必须注入一个 <strong>Context Manager</strong> 来模拟车辆状态。</p>
<ul>
<li><strong>信号仿真 (CAN Simulation)</strong>：<ul>
<li>构造一个 <code>VehicleState</code> 对象，包含：<code>Speed</code>, <code>Gear</code>, <code>WindowPosition</code>, <code>AC_Temp</code>, <code>Passengers [Seat_ID, Status]</code>.</li>
<li><strong>动态变化</strong>：支持剧本（Scenario）定义。例如：第 1 轮对话车速 0，第 3 轮对话车速 80（模拟起步），考察模型是否因为车速变化而拒绝视频播放请求。</li>
</ul>
</li>
<li><strong>API Mocking</strong>：<ul>
<li>拦截模型输出的 <code>open_window(seat="driver")</code> 工具调用。</li>
<li>返回模拟的执行结果：<code>{"status": "success", "new_state": "open"}</code> 或 <code>{"error": "hardware_failure"}</code>。</li>
<li><strong>验证点</strong>：模型收到 error 后，是否能生成合理的安抚话术，而不是复读指令。</li>
</ul>
</li>
</ul>
<h3 id="62-edge-vs-cloud">6.2 端侧 (Edge) vs 云侧 (Cloud) 双栈评测</h3>
<p>车机通常采用“端侧小模型（快速响应/隐私）+ 云侧大模型（复杂知识）”的架构。</p>
<ul>
<li><strong>端侧评测台架</strong>：<ul>
<li>利用 Android Debug Bridge (ADB) 或 SSH 连接开发板（Orin-X / 8295）。</li>
<li>推送量化模型（W4A16, INT8）和测试集到端侧。</li>
<li>执行推理并拉取日志。</li>
</ul>
</li>
<li><strong>一致性校验 (Consistency Check)</strong>：<ul>
<li>对比端侧量化模型与云侧 FP16 模型的输出分布（KL 散度）。</li>
<li>监控端侧特有指标：<strong>RAM 占用峰值</strong>、<strong>NPU 利用率</strong>、<strong>功耗</strong>。</li>
</ul>
</li>
</ul>
<h3 id="63-hil">6.3 硬件在环 (HIL) 辅助</h3>
<p>对于音频和视觉，纯软件 Mock 不够。</p>
<ul>
<li><strong>音频注入</strong>：不直接喂 wav 文件，而是通过声卡回环或专门的音频注入设备，模拟车机麦克风阵列的信号路径（考察 AEC 回声消除和降噪算法对 ASR 的影响）。</li>
<li><strong>时延分段统计</strong>：<ul>
<li>在评测框架中埋点，精确统计：<ul>
<li><code>T_ASR</code>: 语音转文字耗时</li>
<li><code>T_NLU</code>: 意图理解耗时</li>
<li><code>T_LLM_FirstToken</code>: 思考首字耗时</li>
<li><code>T_TTS_Ready</code>: 语音合成首包耗时</li>
</ul>
</li>
<li><strong>Rule of Thumb</strong>: 驾舱交互要求 <code>T_ASR_End</code> 到 <code>T_TTS_Start</code> (响应延迟) &lt; 800ms ~ 1.2s。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="7">7. 本章小结</h2>
<ul>
<li><strong>架构解耦</strong>：Adapter 负责兼容，Runner 负责调度，Scorer 负责裁判，三者分离是平台可维护的关键。</li>
<li><strong>数据决定上限</strong>：多模态评测中，视频解码、音频采样的确定性和缓存策略决定了评测的稳定性和速度。</li>
<li><strong>持续集成</strong>：评测不是一次性的活动，而是研发流水线中的“心跳”，必须分级进行。</li>
<li><strong>车规级要求</strong>：驾舱一体评测需要引入“虚拟车身”和“硬件约束”，关注端云一致性与全链路时延。</li>
</ul>
<hr />
<h2 id="8">8. 练习题</h2>
<h3 id="50">基础题 (50%)</h3>
<ol>
<li><strong>架构理解</strong>：画出从 Dataset 加载到生成 Final Report 的数据流图，标出哪里需要缓存，哪里可以并发。</li>
<li><strong>配置设计</strong>：设计一个 YAML 配置文件片段，描述一个名为 "traffic_sign_recognition" 的评测任务，包含 dataset path, metric (accuracy), 和一个特定的 prompt template。</li>
<li><strong>指标计算</strong>：编写伪代码，实现一个名为 <code>ResponseDumper</code> 的类，具备 <code>dump(sample_id, input, output)</code> 方法，要求能够处理程序崩溃后的数据完整性（提示：flush 和 append）。</li>
</ol>
<h3 id="50_1">挑战题 (50%)</h3>
<ol>
<li><strong>流式评测设计</strong>：对于 ASR 任务，设计一个 Runner，模拟实时音频流输入（chunk by chunk），并计算“用户说完话到文字上屏”的延迟。如何确保评测的可复现性？</li>
<li><strong>训练数据排查</strong>：假设评测发现模型在“打开天窗”这个指令上表现极好（100%），但在“打开遮阳帘”上表现极差（0%）。设计一个自动化的反查流程，利用向量检索技术分析训练数据分布的差异。</li>
<li><strong>车端 Mock 剧本</strong>：编写一个 JSON 格式的测试剧本，模拟用户在驾驶过程中（Speed &gt; 0），尝试进行“看视频”操作。剧本应包含车辆状态变化、用户的多轮对话输入、以及预期的模型行为（拒绝并建议听音频）。</li>
</ol>
<details>
<summary>点击查看提示 (Hint)</summary>
<ul>
<li><strong>基础题3 Hint</strong>: 打开文件时使用 mode='a' (append)。每次 write 后调用 <code>file.flush()</code> 或 <code>os.fsync()</code> 强制刷盘。</li>
<li><strong>挑战题1 Hint</strong>: 需要一个 Generator 来按固定时间间隔 yield 音频块。可复现性需要固定 chunk size 和发送间隔，消除系统调度带来的抖动干扰（使用逻辑时间而非挂钟时间）。</li>
<li><strong>挑战题2 Hint</strong>: 对“打开天窗”和“打开遮阳帘”的指令分别做 Embedding，在训练库中搜索近邻。如果前者能搜到大量 exact match，后者搜不到，说明覆盖率不均。</li>
<li><strong>挑战题3 Hint</strong>: 剧本结构应包含 <code>initial_state: {speed: 60}</code>, <code>turns: [{"user": "我想看狂飙", "expect_action": null, "expect_reply_contains": "驾驶中无法观看"}]</code>。</li>
</ul>
</details>
<hr />
<h2 id="9-gotchas">9. 常见陷阱与错误 (Gotchas)</h2>
<ol>
<li><strong>多进程死锁 (Deadlock in Multiprocessing)</strong>:<ul>
<li><em>现象</em>：评测跑到一半卡住，GPU 显存占用 0，无日志输出。</li>
<li><em>原因</em>：PyTorch 的 <code>DataLoader</code> 多进程与 CUDA 初始化冲突，或者 OpenCV 在 fork 模式下的多线程问题。</li>
<li><em>对策</em>：设置 <code>mp.set_start_method('spawn')</code>，或者在 Runner 中只使用多线程 (Threading) 请求 API 服务，而不自己在 Runner 进程内跑推理。</li>
</ul>
</li>
<li><strong>API 欠费或限流导致的“假性零分”</strong>:<ul>
<li><em>现象</em>：Benchmark 分数暴跌。</li>
<li><em>原因</em>：云端 API 返回 429 Too Many Requests，Extractor 提取不到答案，判为错。</li>
<li><em>对策</em>：必须在 Adapter 层捕获 HTTP Error，区分“模型答错”和“服务拒绝”。后者应抛出异常暂停评测或无限重试。</li>
</ul>
</li>
<li><strong>Git LFS 导致的“空文件”</strong>:<ul>
<li><em>现象</em>：视频理解任务全错，日志显示“文件损坏”。</li>
<li><em>原因</em>：拉取仓库时没安装 <code>git-lfs</code>，图片/视频文件实际上只是几 KB 的指针文本。</li>
<li><em>对策</em>：在 Pipeline 初始化阶段检查媒体文件的 Magic Number 或最小文件大小。</li>
</ul>
</li>
<li><strong>Prompts 对齐陷阱</strong>:<ul>
<li><em>现象</em>：对比两个模型时，A 模型用了 CoT Prompt，B 模型用了 Direct Prompt，导致结论不公平。</li>
<li><em>对策</em>：评测框架应强制将 System Prompt 和 User Template 抽离为独立配置，确保对比实验控制变量。</li>
</ul>
</li>
<li><strong>车机 Mock 状态未重置</strong>:<ul>
<li><em>现象</em>：Case 1 把车速设为 120，Case 2 预期是静止场景，但 Runner 没重置状态，导致 Case 2 触发驾驶安全限制。</li>
<li><em>对策</em>：引入 <code>teardown</code> 钩子，每跑完一个 Sample 或 Session，强制重置 Vehicle Mock Context 到默认状态。</li>
</ul>
</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter2.html" class="nav-link prev">← 第 2 章：数据、指标与统计：从“可比”到“可信”</a><a href="chapter4.html" class="nav-link next">第 4 章：ASR 测评（语音识别） →</a></nav>
        </main>
    </div>
</body>
</html>