（交流可以用英文，所有文档中文）

## 项目背景
输出一个多模理解生成 MLLM 大模型测评的中文 markdown教程。 MLLM 模型支持图像/视频/语音/音乐/文字的输入输出。需要单项测评 ASR、TTS、自然图像/视频理解（交通指示牌、signboard OCR、商店人流、停车扫码、天气等）、人头图像视频理解（action unit, blendshape等）、GUI 截屏/录屏理解、文字逻辑性/低幻觉/RAG 的客观打分、文字和语音 role-play的人类主观打分（OOC、情绪、多轮不崩溃, chitchat 场景）、代码生成能力（作为 proxy loss 评测生成逻辑性和 agent 能力）、agent 能力 (ReAct)、GUI 转代码能力等（再想一些）。 系统地设计测评（什么开源数据集可用，什么测评框架适用（OpenCompass，CharacterEval、ScreenSuite 、TTS 的破音瑕疵等（再想一些）），如何实现及时全面的测评，如何方便地做 ablation，如何反查训练数据问题）。每章最后，专门讨论面向车舱环境下的驾舱一体使用（对话 + RAG/和云上 fallback 交互/记忆 + DMS/OMS 输入 + 前后座语音输入输出 + 中控屏 html/UI 控制 + 和地图导航/ POI API 互动（再想一些））。

文件组织是 index.md + chapter1.md + ...
不写代码。
提供 rule-of-thumb。

## 章节结构要求
每个章节应包含：
1. **开篇段落**：简要介绍本章内容和学习目标
2. **文字论述**：以文字论述为主，适当配上ASCII 图说明。
3. **本章小结**：总结关键概念和公式
4. **练习题**：
   - 每章包含6-8道练习题
   - 50%基础题（帮助熟悉材料）
   - 50%挑战题（包括开放性思考题）
   - 每题提供提示（Hint）
   - 答案默认折叠，不包含代码
5. **常见陷阱与错误** (Gotchas)：每章包含该主题的常见错误和调试技巧
