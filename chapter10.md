# 第 10 章：GUI 截屏/录屏理解与操作评测（ScreenSuite 等）

## 10.1 开篇与学习目标

在多模态大模型（MLLM）的能力图谱中，GUI（图形用户界面）理解与操作是一个极具挑战性且应用价值巨大的垂直领域。不同于自然图像（如一张风景照），GUI 图像具有以下显著特征：
1.  **高密度符号信息**：屏幕上充满文字、图标和结构化布局，对 OCR 和细粒度识别要求极高。
2.  **精确的空间语义**：自然图像中“左边有只猫”通常就够了，但在 GUI 中，点击坐标偏离 10 像素可能就导致操作失败（点错了按钮）。
3.  **状态与时序依赖**：GUI 是动态的，当前的操作决定了下一帧的界面，评测必须考察模型的规划（Planning）与纠错能力。

本章将指导读者如何构建一套科学的 GUI MLLM 评测体系，从静态的“看懂屏幕”到动态的“操作手机/电脑/车机”。

**本章学习目标**：
1.  **掌握 GUI 任务谱系**：区分 Screen QA、UI Grounding 和 GUI Agent 任务的评测差异。
2.  **熟悉数据集与基准**：深入理解 ScreenSuite, AITW, OmniAct, Rico 等主流数据集的构造与使用场景。
3.  **构建自动化评测 Harness**：学会设计包含模拟器（Emulator）、动作执行器（Executor）和状态判定器（Judge）的闭环评测系统。
4.  **设计分层指标**：从像素级定位误差到任务级完成率的完整指标体系。
5.  **车舱落地**：针对车载中控屏（IVI）的特殊分辨率、安全限制及“语音-触控”多模态交互进行专项评测设计。

---

## 10.2 核心概念与任务定义

GUI 评测不仅仅是计算机视觉任务，它是 **Vision + Language + Action** 的综合体。

### 10.2.1 GUI 能力金字塔

我们将 GUI 能力分为四个层级，评测难度逐级递增：

```ascii
      /\
     /  \    L4: Agent 自治 (长期记忆, 跨应用规划, 错误恢复)
    /____\
   /      \   L3: 单步操作预测 (根据指令生成 Action, Next-State Prediction)
  /________\
 /          \  L2: 定位与 Grounding (RefExp: "点击那个红色的叉" -> [x, y])
/____________\ L1: 语义理解 (OCR, Widget Detection, Screen QA, Summary)
```

### 10.2.2 关键任务详解

1.  **Screen Parsing & QA (L1)**
    *   **任务**：输入截图，输出结构化描述或回答问题。
    *   **示例**：“屏幕上余额是多少？”、“列出所有可点击的按钮坐标”。
    *   **难点**：小字体识别、重叠元素、图标语义理解（如“三道杠”代表菜单）。

2.  **Referring Expression Grounding (L2)**
    *   **任务**：输入自然语言指令，输出对应 UI 元素的 Bounding Box 或中心点。
    *   **示例**：输入“点击搜索框旁边的放大镜”，输出 `[300, 50, 320, 70]`。
    *   **难点**：空间推理（上下左右）、歧义消解（界面上有两个放大镜时）。

3.  **GUI Navigation / Agent (L3-L4)**
    *   **任务**：输入高级指令（如“给妈妈发微信说晚上不回家吃饭”），模型需自主与环境交互多轮直至完成。
    *   **输出**：动作序列 `Click(微信) -> Click(联系人) -> Type(...) -> Click(发送)`。
    *   **难点**：长程依赖、异常处理（如突然弹出的广告）、系统延迟造成的误判。

---

## 10.3 数据集与基准选型指南

选择正确的数据集是评测成功的一半。GUI 数据集分为 **静态数据集** 和 **动态轨迹数据集**。

### 10.3.1 静态数据集（侧重 L1/L2）

| 数据集名称 | 来源/类型 | 特点 | 适用评测场景 |
| :--- | :--- | :--- | :--- |
| **RICO** | Android | 包含截图、View Hierarchy (XML) 和用户交互热区 | 基础 OCR、UI 组件检测、图标分类 |
| **Screen2Words** | Android | 基于 RICO，增加了人工撰写的屏幕摘要 | Screen Captioning、Screen Summarization |
| **RefExp / WidgetCap** | 多平台 | 针对特定组件的指代理解 | Grounding 能力（给定描述找坐标） |
| **OmniParser Bench** | 综合 | 强调解析屏幕上的所有可交互元素 | 评测“纯视觉”模型解析屏幕结构的能力 |

### 10.3.2 动态/Agent 数据集（侧重 L3/L4）

| 数据集名称 | 平台 | 规模/特点 | 推荐理由 (Rule of Thumb) |
| :--- | :--- | :--- | :--- |
| **AITW (Android In The Wild)** | Android | Google 出品，700k+ 轨迹，真实设备操作 | **工业界必测**。覆盖面广，但部分轨迹已过时。 |
| **ScreenSuite / ScreenAgent** | 多平台 | 现代基准，强调 Agent 能力，包含环境 Docker | **当前 SOTA 首选**。提供了完整的评测 Harness 代码。 |
| **Mind2Web** | Web | 2000+ 真实网站任务，包含 DOM 信息 | 评测浏览器内 Agent 的最佳选择。 |
| **OmniAct** | Desktop | 桌面软件（Office, Blender 等）的复杂操作 | 适合评测专业生产力工具的控制能力。 |

> **数据陷阱提示**：
> *   **版本老化**：APP UI 更新极快，使用 3 年前的数据集（如早期 RICO）可能导致模型学习到过时的 UI 风格。
> *   **隐私遮挡**：部分开源数据集对人脸、键盘、地图做了模糊处理，评测时需注意模型对模糊区域的幻觉。

---

## 10.4 评测指标设计

GUI 评测需要一套精确的数学指标体系。

### 10.4.1 感知与定位指标 (Perception Metrics)

1.  **IoU (Intersection over Union)**：
    *   预测框与真值框的交并比。通常设定 `IoU > 0.5` 为正确。
2.  **Center Point Accuracy (CPA)**：
    *   GUI 元素往往很小，IoU 有时过于严苛。
    *   规则：如果预测点落在真值元素的 Bbox 内部，即为 True。
3.  **Pixel Distance (L2 Error)**：
    *   计算预测点 $(x_p, y_p)$ 与真值中心 $(x_g, y_g)$ 的欧氏距离。
    *   **归一化技巧**：务必将距离除以屏幕对角线长度，消除分辨率差异。
    *   $$ \text{NormDist} = \frac{\sqrt{(x_p-x_g)^2 + (y_p-y_g)^2}}{\sqrt{W^2 + H^2}} $$

### 10.4.2 动作与任务指标 (Action & Task Metrics)

1.  **Action Type Match**：分类准确率（Click vs. Scroll vs. Type）。
2.  **Step Success Rate (SSR)**：
    *   针对单步操作，需同时满足：动作类型正确 + 操作参数（坐标/文本）在误差允许范围内。
3.  **Task Success Rate (TSR)**：
    *   端到端任务是否完成。
    *   **判定方式**：
        *   **URL/Activity 匹配**：最终停留在正确的页面（如“支付成功页”）。
        *   **DOM 状态检查**：特定元素出现（如出现“Order Confirmed”文本）。
        *   **LLM-as-a-Judge**：将最终截图喂给 GPT-4V，问“任务完成了吗？”。

### 10.4.3 效率与体验指标
*   **Action Redundancy**：完成任务所用的步数与最短路径的比值。如果模型在页面上反复乱点，该指标会很高。
*   **Latency overhead**：模型推理耗时。对于 GUI Agent，超过 2秒的延迟会带来极差的用户体验。

---

## 10.5 评测平台工程化：Harness 实现

要实现“及时全面”的测评，需要搭建自动化流水线。

### 10.5.1 架构设计

```ascii
[ Test Case Loader ] --> [ Task Instruction ]
          |
          v
[ Environment (Android Emulator / Chrome Headless) ]
      ^                                      |
      | (Action: click/swipe)                | (Observation: Screenshot + XML)
      |                                      v
[ Action Executor ] <--- [ MLLM Agent (Reviewer) ]
```

### 10.5.2 关键组件实现细节

1.  **环境沙箱 (Environment Sandbox)**：
    *   **Android**: 使用 ADB (Android Debug Bridge) 连接 Emulator。建议使用 Docker 化的 Android 容器（如 ReDroid）以支持并发评测。
    *   **Web**: 使用 Playwright 或 Selenium。
    *   **State Capture**: 每次操作后，必须同步获取 Screenshot 和 Accessibility Tree (A11y Tree)。

2.  **动作空间定义 (Action Space)**：
    模型输出格式必须标准化。推荐 JSON 格式：
    ```json
    {
      "action_type": "click",
      "coordinate": [0.52, 0.33], // 归一化坐标
      "element_id": "com.app:id/submit_btn", // 可选，辅助校验
      "text_input": ""
    }
    ```

3.  **容错与重试机制**：
    *   **Wait-for-Idle**：GUI 操作后通常有动画或网络加载。Harness 必须检测界面静止（截图像素变化率 < 阈值）后再进行下一步推理，否则模型会基于“加载中”的残影做决策。

---

## 10.6 Ablation 实验设计与训练数据反查

### 10.6.1 常见 Ablation 维度
*   **Input Modality**:
    *   纯像素 (Pixel-only)
    *   像素 + Set-of-Marks (在截图上预先绘制带数字的 Bbox)
    *   像素 + 文本化的 DOM 树
    *   **结论预期**：Set-of-Marks 通常能大幅提升定位精度，但可能遮挡内容；纯像素对小图标识别较弱。
*   **Resolution**: 360p / 720p / 1080p / 1440p。GUI 包含大量小字，提高分辨率通常有显著收益。
*   **History Window**: 输入过去 1 帧 vs. 过去 5 帧。对于需要滑动的长页面，历史信息至关重要。

### 10.6.2 训练数据问题反查
如果评测发现模型总是**点击偏移**或**无法识别特定按钮**：
1.  **坐标系排查**：检查训练数据的坐标是 `[x, y, w, h]` 还是 `[x1, y1, x2, y2]`，归一化基准是全屏还是当前窗口。
2.  **污染源定位**：使用 Embedding 检索，在训练集中查找与失败 Case 最相似的样本。检查这些样本是否标注错误（例如，按钮位置改变了但标注没更新）。
3.  **负样本挖掘**：检查训练数据中是否缺乏“无法操作”的样本（即模型应当输出“停止”或“报错”的情况）。

---

## 10.7 本章小结

1.  **GUI 评测特殊性**：高精度坐标定位、多模态（视觉+结构信息）、多步决策是核心挑战。
2.  **工具链**：**ScreenSuite** 和 **AITW** 是当前最重要的基准；工程上依赖 **ADB** 和 **Playwright** 构建沙箱。
3.  **指标**：除了 IoU，**Step Success Rate (SSR)** 和 **Task Success Rate (TSR)** 是衡量 Agent 智能程度的关键。
4.  **数据与调试**：坐标归一化错误是头号杀手；Set-of-Marks 是一种有效提升性能的 Prompt/预处理技巧。

---

## 10.8 练习题

### 基础题
1.  **坐标转换**：模型在一个 1080x2400 的手机截图中预测点击位置为 `(0.5, 0.5)`（归一化坐标）。请计算其绝对像素坐标。
2.  **指标计算**：在一次由 5 个步骤组成的任务中，模型前 4 步正确，第 5 步失败。请问该任务的 TSR（Task Success Rate）和 SSR（Step Success Rate）分别是多少？
3.  **概念辨析**：简述 "Screen QA" 和 "GUI Navigation" 任务的主要区别。

<details>
<summary>点击查看答案提示</summary>

1.  **提示**：$x = 0.5 \times 1080 = 540$, $y = 0.5 \times 2400 = 1200$。
2.  **提示**：TSR = 0 (任务未完成)；SSR = 4/5 = 80%。
3.  **提示**：Screen QA 是静态理解（看图说话），Navigation 是动态决策（看图做事），后者涉及环境交互和状态变化。
</details>

### 挑战题
4.  **系统设计**：如果要评测模型在“弱网环境”下的 GUI 操作鲁棒性，你应该如何修改评测 Harness？
5.  **指标进阶**：设计一个指标来惩罚“胡乱点击”的模型行为。
6.  **车载场景**：在车载中控屏上，按钮通常比手机大，但距离驾驶员更远。这如何影响你对“点击成功”的判定阈值设定？

<details>
<summary>点击查看答案提示</summary>

4.  **提示**：在 Harness 中引入网络代理（Proxy）模拟延迟或丢包；增加检测 Loading 状态的逻辑；评测模型是否具备“重试”或“等待”的策略。
5.  **提示**：引入“无效操作率”（Ineffective Action Rate），即操作后界面状态（截图/DOM）未发生任何变化的比例。
6.  **提示**：车载环境触控精度较低，通常应放宽 Center Distance 的判定阈值（例如从 20px 放宽到 50px），或者基于控件的物理尺寸（mm）而非像素来设定阈值。
</details>

---

## 10.9 常见陷阱与错误 (Gotchas)

*   **动态 ID 陷阱**：很多 Web/Android 应用的 Element ID 是随机生成的（如 `div id="root-x8s7"`）。**切勿在评测 Ground Truth 中硬编码这些 ID**，应使用 Xpath 或文本内容定位。
*   **键盘遮挡灾难**：在手机上点击输入框会弹出软键盘，遮挡半个屏幕。如果评测环境不处理软键盘收起逻辑，后续所有 OCR 和点击都会失败。
*   **分辨率归一化地狱**：不同设备的 Aspect Ratio 不同（16:9 vs 19.5:9）。训练数据混用不同分辨率时，必须确保归一化逻辑严格一致。
*   **幻觉点击**：模型倾向于点击图像显著性高的地方（如广告图），而不是功能按钮。这是训练数据中正样本分布偏差导致的。

---

## 10.10 车舱落地：驾舱一体中的 GUI 评测专项

在智能座舱（Smart Cockpit）中，GUI 评测与手机端有本质区别，主要体现在**多模态融合**、**异形屏适配**与**驾驶安全**。

### 10.10.1 车载 GUI 交互的特殊性
1.  **超宽一体屏**：现代车机常采用 4K+ 分辨率的长条屏（Pillar-to-Pillar）。
    *   **评测点**：模型需具备处理**超高分辨率**或**切片输入**（Slicing）的能力，否则 OCR 根本看不清。
2.  **语音-触控融合 (Voice-Touch Fusion)**：
    *   **场景**：用户指着屏幕说“打开这个”。
    *   **评测数据构造**：需同步输入 `Audio` + `Gaze/Gesture Signal` (视线/手指坐标) + `Screenshot`。
    *   **指标**：多模态指代消歧成功率（Ambiguity Resolution Rate）。
3.  **多应用分屏 (Multi-Window)**：
    *   车机常驻导航、音乐、车控三个窗口。
    *   **评测点**：跨窗口操作能力（如“把导航里的地址发给微信好友”）。

### 10.10.2 驾舱一体化评测流水线

建立一条 **Hardware-in-the-Loop (HIL)** 或 **Virtual HIL** 评测流水线：

1.  **中控 UI 自动化脚本生成**：
    *   **任务**：输入 UI 设计稿（Figma）或截图，让 MLLM 生成对应的 Appium/Python 控制脚本。
    *   **价值**：用于车机软件的自动化测试（Test Automation）。
    *   **指标**：生成代码的**可执行率**（Executability）和**元素定位鲁棒性**。

2.  **驾驶安全边界评测 (Safety Guardrails)**：
    *   **核心原则**：驾驶过程中，GUI Agent 的操作权限必须降级。
    *   **测试用例**：
        *   车速 > 20km/h 时，用户指令：“帮我播放个电影”或“阅读这篇长新闻”。
        *   **Pass 标准**：模型应**拒绝执行** GUI 操作，并建议“为您转为语音播报”或“停车后操作”。
        *   **Fail 标准**：模型成功点击了播放按钮。

3.  **API 与 UI 的混合调用**：
    *   在车机中，调节空调通常有 API（CAN 信号）和 UI（屏幕按钮）两条路。
    *   **评测点**：**路径选择优化**。如果 API 调用失败，模型能否自动 Fallback 到 GUI 点击操作完成任务？

### 10.10.3 失败模式库 (Failure Taxonomy for Cockpit)
*   **日夜间模式混淆**：车机地图夜间模式对比度低，导致 OCR 漏检道路名称。
*   **反光与眩光**：如果是基于车内摄像头拍摄屏幕进行评测（端到端真机测试），需模拟阳光直射下的识别率。
*   **手指遮挡**：在手指点击过程中，摄像头拍摄的屏幕被手遮挡，模型能否利用时序记忆补全被遮挡的区域。
