# 第 16 章：GUI→代码 + 端到端驾舱一体基准（系统集成/回归/反查）

## 16.1 开篇：从“单点优异”到“系统可用”

在前十五章中，我们分别对 ASR、TTS、视觉理解、RAG、逻辑推理等模块进行了独立的“体检”。然而，智能座舱（Smart Cockpit）不是零件的堆砌，而是一个有机的整体。用户的指令往往是模糊的、跨模态的，且发生在驾驶这一高风险、高认知负荷的场景下。

一个在 MMLU（文本逻辑）上跑分很高的模型，可能会在车速 120km/h 时因为输出了 500 字的冗长回答而导致严重的体验事故；一个在静态 VQA（视觉问答）上表现出色的模型，可能会因为无法处理车载摄像头的鱼眼畸变或夜间眩光而产生由于“误看”导致的“误操作”。

**本章核心目标**：
1.  **GUI → 代码（Generative UI）评测**：测评模型能否理解 UI 设计稿或自然语言意图，直接生成适配车机的前端代码（HTML/QML/Android XML），实现“所见即所得”的动态交互。
2.  **端到端驾舱一体集成评测**：构建“数字孪生”级的仿真基准，涵盖多模态冲突仲裁、安全边界守护、时延预算控制。
3.  **闭环反查体系**：建立从系统级故障（System Failure）自动追溯到训练数据源头（Data Origin）的调试链路。

**学习目标**：
- 掌握 GUI 生成任务中“结构相似度”与“渲染一致性”的客观打分方法。
- 设计覆盖 Level 1（指令）到 Level 3（复杂博弈）的端到端测试场景库。
- 理解车载环境下的特殊约束：多音区仲裁、驾驶分心规避、离线/在线混合架构测评。
- 学会利用 Vector Retrieval 和 Influence Analysis 进行训练数据污染反查。

---

## 16.2 GUI → 代码能力评测：动态界面的生成与还原

智能座舱的演进方向是 **Generative UI（生成式界面）**。传统的车机界面是写死的，而 MLLM 赋能的车机可以根据用户需求即时生成临时组件（Widget）。例如，当用户说“对比一下这三家充电站的停车费和快充功率”时，系统不应只是朗读，而应实时生成一个对比表格卡片。

### 16.2.1 任务定义与输入输出
*   **输入 (Input)**：
    *   **视觉模态**：UI 设计稿（Figma 导出图）、手绘草图、或现有的屏幕截图（用于 UI 修改任务）。
    *   **文本模态**：自然语言指令（如“把背景改成深色模式，按钮放大”）、UI 描述文档（DSL）。
    *   **约束条件**：车机屏幕分辨率（e.g., 2560x1440）、特定设计规范（Design Token，如字体大小限制）。
*   **输出 (Output)**：
    *   可执行代码：HTML/Tailwind/React，或车载专用的 QML / Android Declarative XML。
    *   资源引用：图标、图片的占位符或真实链接。

### 16.2.2 数据集构建策略
由于车机 UI 属于垂直领域，公开数据集（如 WebSight）往往不够用，需自建：
1.  **逆向工程法**：从现有的车机系统（Android Automotive）中提取布局文件（XML）和对应的渲染截图，构建 <截图, 代码> 对。
2.  **组件化合成**：利用 Playwright 或 Selenium，基于一套 UI 组件库自动随机生成数万种布局组合，保存截图和 DOM 树作为真值。
3.  **设计稿转译**：收集设计师的 Figma 稿，人工清洗图层结构，导出为“清洁”的代码作为 Ground Truth。

### 16.2.3 核心指标体系
评测不仅仅看代码能不能跑，核心在于**“长得像不像”（视觉）**和**“能不能用”（交互）**。

#### A. 视觉一致性 (Visual Consistency)
1.  **Pixel-Level (像素级)**：
    *   **RMSE / SSIM**：计算渲染图与真值图的差异。
    *   *局限性*：若生成的按钮仅仅向右偏移了 2px，SSIM 会下降，但对用户体验影响极小。
2.  **Perceptual-Level (感知级)**：
    *   **LPIPS / DreamSim**：利用深度特征（如 VGG/CLIP）计算图像距离，判断“风格”和“结构”是否一致，对微小像素偏移不敏感。
3.  **OCR 辅助验证**：
    *   对渲染图进行 OCR，检查文字内容是否正确、是否存在乱码或幻觉文本。

#### B. 结构与代码质量 (Structural & Code Quality)
1.  **DOM Tree Match (Tree Edit Distance)**：
    *   将生成的 HTML/XML 解析为树结构，计算将其转换为真值树所需的最少编辑操作（增删改）。
    *   *Rule of Thumb*：这是衡量 UI 逻辑正确性的**金标准**。
2.  **Element Recall (元素召回率)**：
    *   关键组件（如“确认”按钮、导航栏、价格文本）是否存在。漏掉功能性组件是严重错误。
3.  **Box Alignment (布局对齐)**：
    *   检查父子元素的包含关系（IoU）和兄弟元素的相对位置（Relative Position）。

#### C. 车载专项指标 (Automotive Specifics)
1.  **Glanceability (易瞥性)**：
    *   自动计算文本对比度是否符合 WCAG AAA 标准（车载要求更高）。
    *   检查字体物理尺寸（需结合 DPI 计算）是否满足最小可视标准（如 >6mm）。
2.  **Touch Target Size (触控热区)**：
    *   分析代码中的 padding/margin 和元素大小，确保可点击区域大于 44x44dp（防止驾驶误触）。

---

## 16.3 端到端驾舱一体基准 (E2E Cockpit Benchmark)

这是将本书前 15 章内容串联起来的“终极考试”。我们需要构建一个**虚拟仿真器（Simulator）**，模拟真实世界的驾驶、网络波动和用户行为。

### 16.3.1 评测架构设计：仿真与拦截
不依赖真车的离线评测架构（Hardware-in-the-Loop 或 Pure Software Simulation）：

```ascii
[ 场景控制器 (Scenario Conductor) ]
       | 控制天气、路况、GPS、车辆信号
       v
[ 仿真环境 (Simulator) ] ----> [ 信号注入 (Signal Injection) ]
       |                                   |
       |-- 视频流 (DMS/OMS/ADAS) -----------> [ 待测 MLLM 系统 ]
       |-- 音频流 (模拟麦克风阵列) ----------> [ (SUT) ]
       |-- CAN 总线 (车速/档位/电量) --------> |
                                           |
       <------- [ 动作拦截 (Action Trap) ] <---|
                |-- TTS 音频输出
                |-- 屏幕 UI 更新 (DOM/Screenshot)
                |-- 车控指令 (API Calls)
                |
       v
[ 自动裁判 (The Judge / Oracle) ]
```

### 16.3.2 场景库分级 (The Scenario Pyramid)
测试用例应按复杂度分层，确保既能测出基础能力，又能测出系统边界。

| 等级 | 场景类型 | 示例 | 考核点 |
| :--- | :--- | :--- | :--- |
| **L1** | **原子指令** | “打开主驾车窗”、“导航到天安门” | 意图分类、槽位填充、API 映射准确率 |
| **L2** | **多轮与上下文** | “帮我找个加油站” -> “太远了” -> “这就去” | 指代消解、上下文记忆、意图漂移检测 |
| **L3** | **跨模态融合** | 手指窗外问“那个红色的楼是什么？” | 视觉定位（Gaze+Object Det）、地图 POI 融合、知识检索 |
| **L4** | **多音区冲突仲裁** | 后排：“太吵了”；副驾：“声音大点” | 声源定位、优先级策略、多意图理解 |
| **L5** | **长链路 Agent** | “规划一条去西藏的路线，沿途要有充电桩和宠物友好的酒店” | 复杂规划、多工具调用（地图+充电+酒店APP）、长时记忆 |

### 16.3.3 关键仲裁机制评测 (Arbitration Evaluation)
在车内，多个模态的输入可能冲突，系统必须依据**置信度**和**优先级**做出裁决。

*   **测试案例**：
    *   *输入*：语音指令“关闭车窗”（ASR 置信度 0.8），同时手势指令“挥手打开车窗”（视觉置信度 0.9）。
    *   *预期*：通常设定物理交互（手势/触控）优先级高于语音，或系统反问“您是想打开还是关闭？”
*   **评测方法**：构造冲突样本对（Pairwise Conflict），检查系统的决策日志是否符合预设的 Priority Matrix。

---

## 16.4 安全、人因与鲁棒性 (Safety & Human Factors)

在驾舱环境下，**安全性**和**不打扰**是最高优先级。

### 16.4.1 认知负荷控制 (Cognitive Load)
*   **速度敏感性测试**：
    *   *场景*：询问“特斯拉的股价走势”。
    *   *Condition A（静止）*：允许展示详细 K 线图，TTS 详细播报。
    *   *Condition B（车速 80km/h）*：**只能**简短语音播报当前价格，屏幕仅显示大号数字，禁止复杂图表。
    *   *评测指标*：不同车速下的输出文本长度、UI 信息密度（Information Density）。
*   **交互轮次限制**：
    *   高风险操作（如修改系统设置）在行车中应被强制阻断或简化为“一步操作”。

### 16.4.2 幻觉与误导 (Safety Critical Hallucination)
*   **车辆状态诚实性**：
    *   断开 CAN 信号连接，问模型“现在电量多少？”
    *   *Pass*：“抱歉，当前无法获取车辆数据。”
    *   *Fail*：“当前电量 80%。”（瞎编数据在驾驶场景是致命的）。
*   **外部知识边界**：
    *   询问交通法规、急救知识。模型必须引用权威数据或拒答，严禁似是而非的建议。

### 16.4.3 鲁棒性与兜底 (Robustness & Fallback)
*   **网络弱网/断网测试**：
    *   模拟隧道场景（丢包率 50% 或完全断网）。
    *   *预期*：本地车控（打开空调）必须 100% 成功；在线查询（天气）应优雅降级提示，不应卡死 Loading。
*   **ASR 噪声注入**：
    *   叠加 80dB 的胎噪和风噪，测试指令唤醒率和误触发率（False Positive）。

---

## 16.5 系统级 Ablation 与数据反查 (Traceback)

当端到端指标（如“任务成功率”）下降时，必须有一套工程化的方法快速定位“锅”在哪个模块，并追溯到是哪批数据导致的。

### 16.5.1 模块归因分析 (Module Attribution)
利用 **Oracle Injection（上帝注入）** 方法进行消融实验：

1.  **定位 ASR 问题**：将真实的 ASR 识别结果替换为“完美人工转写文本”。若系统成功率大幅提升，说明瓶颈在 ASR。
2.  **定位 RAG 问题**：在 Context 中强制注入正确的知识片段。若生成质量提升，说明是 Retriever（检索）失效。
3.  **定位 Planner 问题**：给定完美意图和知识，若模型仍无法调用正确的 API，说明是 Agent/Planner 逻辑能力不足。

### 16.5.2 训练数据反查工作流 (Data Traceback Workflow)
发现严重 Bad Case（如模型学会了带有攻击性的回复，或对某个指令总是理解反了）时，如何修？

1.  **Embedding Retrieval (向量检索)**：
    *   将 Bad Case 的 Prompt 编码为向量。
    *   在 SFT 数据集和 Pre-train 数据索引中检索 Top-K 相似样本。
    *   *目的*：找出是否有标注错误的样本直接“教坏”了模型。
2.  **Influence Functions (影响函数)**：
    *   计算训练集中哪些样本对当前 Bad Case 的 Loss 梯度贡献最大。
    *   *目的*：找出那些语义不相似但梯度方向导致模型跑偏的隐蔽样本（如某些含有毒性模式的数据）。
3.  **元数据审计 (Metadata Audit)**：
    *   检查检索出的“有毒样本”来源：是哪个供应商标注的？是哪天的爬虫数据？
    *   *行动*：将该来源/批次的数据全部隔离重审，进行“数据回滚”。

---

## 16.6 交付物与上车标准 (Deliverables)

在模型 OTA 推送给用户之前，必须产出标准化的交付物。

### 16.6.1 车载 Model Card
除了常规的模型参数，还需包含：
*   **适用工况**：支持的方言列表、支持的噪声分贝上限。
*   **安全声明**：已知的幻觉类型、已通过的红队测试（Red Teaming）场景。
*   **硬件需求**：NPU 算力需求（TOPS）、内存峰值（Peak Memory）、量化精度（INT4/INT8）。

### 16.6.2 回归门禁 (Regression Gate)
建立包含 1000+ 个核心场景的自动化回归集（Golden Set）：
*   **高频车控**（空调、车窗、座椅）：通过率必须 **100%**。
*   **法律法规**（不系安全带提示）：必须准确触发。
*   **性能指标**：首字延迟（TTFT）不得高于上一版本的 5%。

---

## 16.7 本章小结

第 16 章是全书的总结。我们从单点能力的测评走向了系统的**整体性、安全性与工程化**。
*   **GUI→代码**不仅要看像素，更要看 DOM 结构和车载适配性（字号、热区）。
*   **端到端测评**不仅要看准确率，更要看多模态仲裁、认知负荷控制和降级策略。
*   **数据反查**是 MLLM 开发闭环中最关键的一环，它赋予了我们面对黑盒模型时的调试能力。

至此，您已掌握了从模型选型、单项调优到系统集成上车的全套 MLLM 测评方法论。

---

## 16.8 练习题

### 基础题
1.  **GUI 指标**：为什么在评测车载 UI 生成时，需要特别关注“Text Contrast”（文本对比度）和“Touch Target Size”（触控热区）？
2.  **场景分级**：请设计一个 Level 4（多音区冲突）的测试用例，并描述理想的系统行为。
3.  **Ablation**：在 E2E 测试中，发现“打开天窗”的指令执行失败。请列出至少 3 个可能的故障环节（从输入到执行）。

### 挑战题
4.  **实验设计**：设计一个针对“后排遗留儿童检测（OMS）+ 语音告警”的端到端评测方案。你需要考虑到哪些具体的 Corner Case（极端情况）？如何量化“误报带来的骚扰度”？
5.  **反查策略**：如果模型在回答“如何开启自动驾驶”时，错误地引用了另一款车型的操作步骤。请描述你如何利用 RAG 的中间结果和训练数据索引来定位问题根源。
6.  **思考题**：在未来的完全自动驾驶（L4/L5）场景下，座舱 MLLM 的测评重点会发生什么变化？（提示：从驾驶辅助转向娱乐/办公/生活空间）。

> **Hint 4**: 极端情况包括：大件行李像人、宠物狗、极度黑暗环境。误报度量可以用“每千公里误报次数”结合用户手动取消告警的比例。
> **Hint 5**: 检查 RAG 召回的文档块是否包含了错误车型的文档（检索错误）；如果文档正确，检查 SFT 数据中是否有类似的“张冠李戴”的问答对（模型生成错误）。

<details>
<summary>点击查看练习题答案思路</summary>

1.  **GUI 指标**：车载环境光线变化剧烈，高对比度保证可视性；驾驶中操作不稳定，大热区保证盲操安全。
2.  **Level 4 案例**：
    *   *输入*：主驾说“导航去公司”，后排说“我要看动画片”。
    *   *理想行为*：系统识别出两个声源。主驾屏开启导航（优先级高），后排屏播放动画片（分区独立）。若只有一个屏幕，则主驾导航优先，后排需求挂起或仅音频满足。
3.  **故障环节**：
    *   ASR 识别错误（听成“打开天窗” vs “打开天窗帘”）。
    *   NLU 意图分类错误（识别为 Search intent 而非 Control intent）。
    *   Slot Filling 错误（没识别出是对“天窗”操作）。
    *   车控 API 映射错误（调用了错误的 Function ID）。
    *   执行端失败（硬件故障或条件不满足，如雨天自动锁死）。
4.  **OMS 评测**：
    *   *Corner Cases*：玩偶/抱枕误检、后排乘客睡觉不动（类似遗留）、地库全黑环境。
    *   *误报量化*：FP Rate（单位时间内误报数）；Interruption Cost（用户打断/关闭提示的耗时）。
5.  **反查策略**：
    *   第一步：检查 Retrieval 阶段召回的 Chunks。如果是召回了错误车型的说明书，则是 Embedding 区分度不够或元数据过滤失效。
    *   第二步：如果召回正确，检查生成模型。检索 SFT 数据中关于“自动驾驶开启”的样本，看是否存在类似的错误关联。
6.  **L4/L5 变化**：
    *   **安全性**：对驾驶干扰的限制降低，允许沉浸式体验。
    *   **任务类型**：从“车辆控制/导航”转向“会议助理/沉浸式娱乐/购物”。
    *   **多模态**：更多手势、视线交互，甚至脑机接口。
</details>

---

## 16.9 常见陷阱与错误 (Gotchas)

1.  **“真值”的陷阱**：在 GUI 代码生成评测中，直接对比 HTML 字符串（String Match）是毫无意义的。因为 `div class="a b"` 和 `div class="b a"` 功能相同但字符串不同。**必须对比渲染树或渲染图**。
2.  **忽视状态机**：端到端评测不能只看单轮。很多车控功能依赖状态机（State Machine）。例如，“调整后视镜”的前提是“选中了左/右后视镜”。如果评测脚本没有先置状态，会导致大量 False Negative。
3.  **云端依赖症**：很多开发者在办公室网络环境下测评，一切完美。到了地下车库（弱网），系统连唤醒都做不到。**必须在 CI/CD 中强制加入断网/丢包测试环节**。
4.  **过拟合 Golden Set**：如果回归测试集（Golden Set）长期不变，模型可能会通过“背题”来刷高分。必须引入**动态测试集**，定期变换说法、更换槽位实体（如把“打开空调”变为“打开AC”、“开启制冷”）。
